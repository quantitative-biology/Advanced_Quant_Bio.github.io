<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Multivariate analysis: Clustering and Ordination | Building Skills in Quantitative Biology</title>
  <meta name="description" content="4 Multivariate analysis: Clustering and Ordination | Building Skills in Quantitative Biology" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Multivariate analysis: Clustering and Ordination | Building Skills in Quantitative Biology" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="4 Multivariate analysis: Clustering and Ordination | Building Skills in Quantitative Biology" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Multivariate analysis: Clustering and Ordination | Building Skills in Quantitative Biology" />
  
  <meta name="twitter:description" content="4 Multivariate analysis: Clustering and Ordination | Building Skills in Quantitative Biology" />
  

<meta name="author" content="Kim Cuddington, Andrew M. Edwards, Brian Ingalls" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="r-markdown.html"/>
<link rel="next" href="machine-learning-and-classification.html"/>
<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<script src="libs/jquery-3.5.1/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.4.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.57.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.57.1/plotly-latest.min.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<!-- Adding to index.Rmd as per https://stackoverflow.com/questions/41376989/how-to-include-google-analytics-in-an-rmarkdown-generated-github-page -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-Y14SQ7MY4S"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-Y14SQ7MY4S');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { font-weight: bold; } /* Alert */
code span.an { font-style: italic; } /* Annotation */
code span.cf { font-weight: bold; } /* ControlFlow */
code span.co { font-style: italic; } /* Comment */
code span.cv { font-style: italic; } /* CommentVar */
code span.do { font-style: italic; } /* Documentation */
code span.dt { text-decoration: underline; } /* DataType */
code span.er { font-weight: bold; } /* Error */
code span.in { font-style: italic; } /* Information */
code span.kw { font-weight: bold; } /* Keyword */
code span.pp { font-weight: bold; } /* Preprocessor */
code span.wa { font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Welcome!</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#open-science"><i class="fa fa-check"></i><b>1.1</b> Open Science</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#feedback"><i class="fa fa-check"></i><b>1.2</b> Feedback</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#about-the-authors"><i class="fa fa-check"></i><b>1.3</b> About the authors</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#acknowledgments"><i class="fa fa-check"></i><b>1.4</b> Acknowledgments</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#citation"><i class="fa fa-check"></i><b>1.5</b> Citation</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="git-and-github.html"><a href="git-and-github.html"><i class="fa fa-check"></i><b>2</b> Git and GitHub</a>
<ul>
<li class="chapter" data-level="2.1" data-path="git-and-github.html"><a href="git-and-github.html#what-are-git-and-github-and-how-might-they-be-useful"><i class="fa fa-check"></i><b>2.1</b> What are Git and GitHub and how might they be useful?</a></li>
<li class="chapter" data-level="2.2" data-path="git-and-github.html"><a href="git-and-github.html#you-just-want-do-download-someone-elses-code-from-their-github-repository"><i class="fa fa-check"></i><b>2.2</b> You just want do download someone else’s code from their GitHub repository</a></li>
<li class="chapter" data-level="2.3" data-path="git-and-github.html"><a href="git-and-github.html#motivation-for-learning-more"><i class="fa fa-check"></i><b>2.3</b> Motivation for learning more</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="git-and-github.html"><a href="git-and-github.html#example-application-pacific-hake-stock-assessment"><i class="fa fa-check"></i><b>2.3.1</b> Example application – Pacific Hake stock assessment</a></li>
<li class="chapter" data-level="2.3.2" data-path="git-and-github.html"><a href="git-and-github.html#examples-of-what-we-can-avoid"><i class="fa fa-check"></i><b>2.3.2</b> Examples of what we can avoid</a></li>
<li class="chapter" data-level="2.3.3" data-path="git-and-github.html"><a href="git-and-github.html#example-of-advantages-that-arise-from-using-github"><i class="fa fa-check"></i><b>2.3.3</b> Example of advantages that arise from using GitHub</a></li>
<li class="chapter" data-level="2.3.4" data-path="git-and-github.html"><a href="git-and-github.html#why-this-course"><i class="fa fa-check"></i><b>2.3.4</b> Why this course?</a></li>
<li class="chapter" data-level="2.3.5" data-path="git-and-github.html"><a href="git-and-github.html#does-it-matter-which-computer-language-my-code-is-in"><i class="fa fa-check"></i><b>2.3.5</b> Does it matter which computer language my code is in?</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="git-and-github.html"><a href="git-and-github.html#getting-set-up-for-the-first-time"><i class="fa fa-check"></i><b>2.4</b> Getting set up for the first time</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="git-and-github.html"><a href="git-and-github.html#what-you-will-end-up-having-installed"><i class="fa fa-check"></i><b>2.4.1</b> What you will end up having installed</a></li>
<li class="chapter" data-level="2.4.2" data-path="git-and-github.html"><a href="git-and-github.html#text-editor"><i class="fa fa-check"></i><b>2.4.2</b> Text Editor</a></li>
<li class="chapter" data-level="2.4.3" data-path="git-and-github.html"><a href="git-and-github.html#install-the-git-application-on-your-machine"><i class="fa fa-check"></i><b>2.4.3</b> Install the Git application on your machine</a></li>
<li class="chapter" data-level="2.4.4" data-path="git-and-github.html"><a href="git-and-github.html#git-shell-guis-and-rstudio"><i class="fa fa-check"></i><b>2.4.4</b> Git shell, GUIs and RStudio</a></li>
<li class="chapter" data-level="2.4.5" data-path="git-and-github.html"><a href="git-and-github.html#powershell-and-posh-git"><i class="fa fa-check"></i><b>2.4.5</b> Powershell and posh-git</a></li>
<li class="chapter" data-level="2.4.6" data-path="git-and-github.html"><a href="git-and-github.html#create-a-directory-to-keep-all-your-git-tracked-work"><i class="fa fa-check"></i><b>2.4.6</b> Create a directory to keep all your Git-tracked work</a></li>
<li class="chapter" data-level="2.4.7" data-path="git-and-github.html"><a href="git-and-github.html#install-diffmerge-optional"><i class="fa fa-check"></i><b>2.4.7</b> Install Diffmerge (optional)</a></li>
<li class="chapter" data-level="2.4.8" data-path="git-and-github.html"><a href="git-and-github.html#save-our-template-.gitconfig-file"><i class="fa fa-check"></i><b>2.4.8</b> Save our template <em>.gitconfig</em> file</a></li>
<li class="chapter" data-level="2.4.9" data-path="git-and-github.html"><a href="git-and-github.html#edit-the-.gitconfig-file"><i class="fa fa-check"></i><b>2.4.9</b> Edit the <em>.gitconfig</em> file</a></li>
<li class="chapter" data-level="2.4.10" data-path="git-and-github.html"><a href="git-and-github.html#github-authorisation"><i class="fa fa-check"></i><b>2.4.10</b> GitHub authorisation</a></li>
<li class="chapter" data-level="2.4.11" data-path="git-and-github.html"><a href="git-and-github.html#navigating-in-a-shell"><i class="fa fa-check"></i><b>2.4.11</b> Navigating in a shell</a></li>
<li class="chapter" data-level="2.4.12" data-path="git-and-github.html"><a href="git-and-github.html#one-time-authentication"><i class="fa fa-check"></i><b>2.4.12</b> One-time authentication</a></li>
<li class="chapter" data-level="2.4.13" data-path="git-and-github.html"><a href="git-and-github.html#mac-only-make-your-output-pretty"><i class="fa fa-check"></i><b>2.4.13</b> MAC only: make your output pretty</a></li>
<li class="chapter" data-level="2.4.14" data-path="git-and-github.html"><a href="git-and-github.html#something-to-view-markdown-files-optional"><i class="fa fa-check"></i><b>2.4.14</b> Something to view Markdown files (optional)</a></li>
<li class="chapter" data-level="2.4.15" data-path="git-and-github.html"><a href="git-and-github.html#bonus-keyboard-shortcut-optional"><i class="fa fa-check"></i><b>2.4.15</b> Bonus keyboard shortcut (optional)</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="git-and-github.html"><a href="git-and-github.html#using-git-and-github-to-share-your-own-code"><i class="fa fa-check"></i><b>2.5</b> Using Git and GitHub to share your own code</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="git-and-github.html"><a href="git-and-github.html#definitions"><i class="fa fa-check"></i><b>2.5.1</b> Definitions</a></li>
<li class="chapter" data-level="2.5.2" data-path="git-and-github.html"><a href="git-and-github.html#creating-a-new-repository"><i class="fa fa-check"></i><b>2.5.2</b> Creating a new repository</a></li>
<li class="chapter" data-level="2.5.3" data-path="git-and-github.html"><a href="git-and-github.html#cloning-your-new-repository"><i class="fa fa-check"></i><b>2.5.3</b> Cloning your new repository</a></li>
<li class="chapter" data-level="2.5.4" data-path="git-and-github.html"><a href="git-and-github.html#committing"><i class="fa fa-check"></i><b>2.5.4</b> Committing</a></li>
<li class="chapter" data-level="2.5.5" data-path="git-and-github.html"><a href="git-and-github.html#exercise-1-create-edit-and-commit-simpletext.txt"><i class="fa fa-check"></i><b>2.5.5</b> Exercise 1: create, edit and commit <em>simpleText.txt</em></a></li>
<li class="chapter" data-level="2.5.6" data-path="git-and-github.html"><a href="git-and-github.html#exercise-2-multiple-files"><i class="fa fa-check"></i><b>2.5.6</b> Exercise 2: multiple files</a></li>
<li class="chapter" data-level="2.5.7" data-path="git-and-github.html"><a href="git-and-github.html#what-to-write-in-commit-messages"><i class="fa fa-check"></i><b>2.5.7</b> What to write in commit messages</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="git-and-github.html"><a href="git-and-github.html#using-git-and-github-to-collaborate-with-colleagues"><i class="fa fa-check"></i><b>2.6</b> Using Git and GitHub to collaborate with colleagues</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="git-and-github.html"><a href="git-and-github.html#demonstration-of-collaborating"><i class="fa fa-check"></i><b>2.6.1</b> Demonstration of collaborating</a></li>
<li class="chapter" data-level="2.6.2" data-path="git-and-github.html"><a href="git-and-github.html#a-bit-more-about-git-rebase"><i class="fa fa-check"></i><b>2.6.2</b> A bit more about git rebase</a></li>
<li class="chapter" data-level="2.6.3" data-path="git-and-github.html"><a href="git-and-github.html#fixing-a-conflict"><i class="fa fa-check"></i><b>2.6.3</b> Fixing a conflict</a></li>
<li class="chapter" data-level="2.6.4" data-path="git-and-github.html"><a href="git-and-github.html#exercise-3-collaborating-on-a-single-repository"><i class="fa fa-check"></i><b>2.6.4</b> Exercise 3: collaborating on a single repository</a></li>
<li class="chapter" data-level="2.6.5" data-path="git-and-github.html"><a href="git-and-github.html#collaborating-summary"><i class="fa fa-check"></i><b>2.6.5</b> Collaborating summary</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="git-and-github.html"><a href="git-and-github.html#workflow-tips-when-collaborating"><i class="fa fa-check"></i><b>2.7</b> Workflow tips when collaborating</a></li>
<li class="chapter" data-level="2.8" data-path="git-and-github.html"><a href="git-and-github.html#beyond-the-basics-of-git-and-github-getting-more-advanced"><i class="fa fa-check"></i><b>2.8</b> Beyond the basics of Git and GitHub – getting more advanced</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="git-and-github.html"><a href="git-and-github.html#so-ive-made-some-changes-but-dont-really-want-to-keep-them-git-stash"><i class="fa fa-check"></i><b>2.8.1</b> So I’ve made some changes but don’t really want to keep them – git stash</a></li>
<li class="chapter" data-level="2.8.2" data-path="git-and-github.html"><a href="git-and-github.html#the-power-to-go-back"><i class="fa fa-check"></i><b>2.8.2</b> The power to go back</a></li>
<li class="chapter" data-level="2.8.3" data-path="git-and-github.html"><a href="git-and-github.html#so-how-does-git-do-all-this"><i class="fa fa-check"></i><b>2.8.3</b> So how does Git do all this?</a></li>
<li class="chapter" data-level="2.8.4" data-path="git-and-github.html"><a href="git-and-github.html#git-terminology"><i class="fa fa-check"></i><b>2.8.4</b> Git terminology</a></li>
<li class="chapter" data-level="2.8.5" data-path="git-and-github.html"><a href="git-and-github.html#branching"><i class="fa fa-check"></i><b>2.8.5</b> Branching</a></li>
<li class="chapter" data-level="2.8.6" data-path="git-and-github.html"><a href="git-and-github.html#pull-requests"><i class="fa fa-check"></i><b>2.8.6</b> Pull requests</a></li>
<li class="chapter" data-level="2.8.7" data-path="git-and-github.html"><a href="git-and-github.html#undoing-stuff"><i class="fa fa-check"></i><b>2.8.7</b> Undoing stuff</a></li>
<li class="chapter" data-level="2.8.8" data-path="git-and-github.html"><a href="git-and-github.html#using-r-and-github-within-rstudio"><i class="fa fa-check"></i><b>2.8.8</b> Using R and GitHub within RStudio</a></li>
<li class="chapter" data-level="2.8.9" data-path="git-and-github.html"><a href="git-and-github.html#feedback-1"><i class="fa fa-check"></i><b>2.8.9</b> Feedback</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="r-markdown.html"><a href="r-markdown.html"><i class="fa fa-check"></i><b>3</b> R Markdown</a>
<ul>
<li class="chapter" data-level="3.1" data-path="r-markdown.html"><a href="r-markdown.html#motivation"><i class="fa fa-check"></i><b>3.1</b> Motivation</a></li>
<li class="chapter" data-level="3.2" data-path="r-markdown.html"><a href="r-markdown.html#basic-idea"><i class="fa fa-check"></i><b>3.2</b> Basic idea</a></li>
<li class="chapter" data-level="3.3" data-path="r-markdown.html"><a href="r-markdown.html#simple-example"><i class="fa fa-check"></i><b>3.3</b> Simple example</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="r-markdown.html"><a href="r-markdown.html#exercise-1"><i class="fa fa-check"></i><b>3.3.1</b> Exercise 1</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="r-markdown.html"><a href="r-markdown.html#output-format"><i class="fa fa-check"></i><b>3.4</b> Output format</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="r-markdown.html"><a href="r-markdown.html#exercise-2"><i class="fa fa-check"></i><b>3.4.1</b> Exercise 2</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="r-markdown.html"><a href="r-markdown.html#caching-advanced"><i class="fa fa-check"></i><b>3.5</b> Caching (advanced)</a></li>
<li class="chapter" data-level="3.6" data-path="r-markdown.html"><a href="r-markdown.html#further-reading"><i class="fa fa-check"></i><b>3.6</b> Further reading</a></li>
<li class="chapter" data-level="3.7" data-path="r-markdown.html"><a href="r-markdown.html#using-rstudio"><i class="fa fa-check"></i><b>3.7</b> Using RStudio</a></li>
<li class="chapter" data-level="3.8" data-path="r-markdown.html"><a href="r-markdown.html#feedback-2"><i class="fa fa-check"></i><b>3.8</b> Feedback</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="multi.html"><a href="multi.html"><i class="fa fa-check"></i><b>4</b> Multivariate analysis: Clustering and Ordination</a>
<ul>
<li class="chapter" data-level="4.1" data-path="multi.html"><a href="multi.html#multivariate-resemblance"><i class="fa fa-check"></i><b>4.1</b> Multivariate resemblance</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="multi.html"><a href="multi.html#binary-similarity-metrics"><i class="fa fa-check"></i><b>4.1.1</b> Binary Similarity metrics</a></li>
<li class="chapter" data-level="4.1.2" data-path="multi.html"><a href="multi.html#quantitative-similarity-dissimilarity-metrics"><i class="fa fa-check"></i><b>4.1.2</b> Quantitative similarity &amp; dissimilarity metrics</a></li>
<li class="chapter" data-level="4.1.3" data-path="multi.html"><a href="multi.html#comparing-more-than-two-communitiessamplessitesgenesspecies"><i class="fa fa-check"></i><b>4.1.3</b> Comparing more than two communities/samples/sites/genes/species</a></li>
<li class="chapter" data-level="4.1.4" data-path="multi.html"><a href="multi.html#r-functions"><i class="fa fa-check"></i><b>4.1.4</b> R functions</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="multi.html"><a href="multi.html#cluster-analysis"><i class="fa fa-check"></i><b>4.2</b> Cluster Analysis</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="multi.html"><a href="multi.html#hierarchical-clustering-groups-are-nested-within-other-groups."><i class="fa fa-check"></i><b>4.2.1</b> Hierarchical clustering: groups are nested within other groups.</a></li>
<li class="chapter" data-level="4.2.2" data-path="multi.html"><a href="multi.html#partitional-clustering-and-fuzzy-clustering"><i class="fa fa-check"></i><b>4.2.2</b> Partitional clustering and Fuzzy clustering</a></li>
<li class="chapter" data-level="4.2.3" data-path="multi.html"><a href="multi.html#r-functions-for-clustering"><i class="fa fa-check"></i><b>4.2.3</b> R functions for clustering</a></li>
<li class="chapter" data-level="4.2.4" data-path="multi.html"><a href="multi.html#example-cluster-analysis-of-isotope-data"><i class="fa fa-check"></i><b>4.2.4</b> Example: Cluster analysis of isotope data</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="multi.html"><a href="multi.html#Ord"><i class="fa fa-check"></i><b>4.3</b> Ordination</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="multi.html"><a href="multi.html#PCA"><i class="fa fa-check"></i><b>4.3.1</b> Principal Components Analysis (PCA)</a></li>
<li class="chapter" data-level="4.3.2" data-path="multi.html"><a href="multi.html#principle-coordinates-analysis-pcoa"><i class="fa fa-check"></i><b>4.3.2</b> Principle Coordinates Analysis (PCoA)</a></li>
<li class="chapter" data-level="4.3.3" data-path="multi.html"><a href="multi.html#nonmetric-multidimensional-scaling-nmds"><i class="fa fa-check"></i><b>4.3.3</b> Nonmetric Multidimensional Scaling (nMDS)</a></li>
<li class="chapter" data-level="4.3.4" data-path="multi.html"><a href="multi.html#example-nmds-and-pcoa"><i class="fa fa-check"></i><b>4.3.4</b> Example: nMDS and PCoA</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="multi.html"><a href="multi.html#constrained-ordination"><i class="fa fa-check"></i><b>4.4</b> Constrained Ordination</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="multi.html"><a href="multi.html#redundancy-analysis"><i class="fa fa-check"></i><b>4.4.1</b> Redundancy Analysis</a></li>
<li class="chapter" data-level="4.4.2" data-path="multi.html"><a href="multi.html#example-constrained-ordination"><i class="fa fa-check"></i><b>4.4.2</b> Example: Constrained ordination</a></li>
<li class="chapter" data-level="4.4.3" data-path="multi.html"><a href="multi.html#signficance-tests-for-constrained-ordination"><i class="fa fa-check"></i><b>4.4.3</b> Signficance tests for constrained ordination</a></li>
<li class="chapter" data-level="4.4.4" data-path="multi.html"><a href="multi.html#forward-selection-of-explanatory-variables"><i class="fa fa-check"></i><b>4.4.4</b> Forward Selection of explanatory variables</a></li>
<li class="chapter" data-level="4.4.5" data-path="multi.html"><a href="multi.html#tri"><i class="fa fa-check"></i><b>4.4.5</b> Triplots: Graphing a constrained ordination</a></li>
<li class="chapter" data-level="4.4.6" data-path="multi.html"><a href="multi.html#feedback-3"><i class="fa fa-check"></i><b>4.4.6</b> Feedback</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="multi.html"><a href="multi.html#references"><i class="fa fa-check"></i><b>4.5</b> References</a></li>
<li class="chapter" data-level="4.6" data-path="multi.html"><a href="multi.html#answer-key"><i class="fa fa-check"></i><b>4.6</b> Answer Key</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="machine-learning-and-classification.html"><a href="machine-learning-and-classification.html"><i class="fa fa-check"></i><b>5</b> Machine learning and classification</a>
<ul>
<li class="chapter" data-level="5.1" data-path="machine-learning-and-classification.html"><a href="machine-learning-and-classification.html#logistic-regression"><i class="fa fa-check"></i><b>5.1</b> Logistic regression</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="machine-learning-and-classification.html"><a href="machine-learning-and-classification.html#interpreting-the-logistic-regression"><i class="fa fa-check"></i><b>5.1.1</b> Interpreting the logistic regression</a></li>
<li class="chapter" data-level="5.1.2" data-path="machine-learning-and-classification.html"><a href="machine-learning-and-classification.html#the-confusion-matrix"><i class="fa fa-check"></i><b>5.1.2</b> The confusion matrix</a></li>
<li class="chapter" data-level="5.1.3" data-path="machine-learning-and-classification.html"><a href="machine-learning-and-classification.html#roc-and-auc"><i class="fa fa-check"></i><b>5.1.3</b> ROC and AUC</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="machine-learning-and-classification.html"><a href="machine-learning-and-classification.html#cross-validation"><i class="fa fa-check"></i><b>5.2</b> Cross-validation</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="machine-learning-and-classification.html"><a href="machine-learning-and-classification.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>5.2.1</b> k-Fold Cross-Validation</a></li>
<li class="chapter" data-level="5.2.2" data-path="machine-learning-and-classification.html"><a href="machine-learning-and-classification.html#multiple-logistic-regression"><i class="fa fa-check"></i><b>5.2.2</b> Multiple logistic regression</a></li>
<li class="chapter" data-level="5.2.3" data-path="machine-learning-and-classification.html"><a href="machine-learning-and-classification.html#examples-of-logistic-regression-used-for-classification"><i class="fa fa-check"></i><b>5.2.3</b> Examples of logistic regression used for classification</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="machine-learning-and-classification.html"><a href="machine-learning-and-classification.html#linear-discriminant-analysis-lda"><i class="fa fa-check"></i><b>5.3</b> Linear Discriminant Analysis (LDA)</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="machine-learning-and-classification.html"><a href="machine-learning-and-classification.html#examples-of-discriminant-analysis-used-for-classification"><i class="fa fa-check"></i><b>5.3.1</b> Examples of discriminant analysis used for classification</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="machine-learning-and-classification.html"><a href="machine-learning-and-classification.html#tree-based-methods-for-classification"><i class="fa fa-check"></i><b>5.4</b> Tree-based methods for classification</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="machine-learning-and-classification.html"><a href="machine-learning-and-classification.html#classification-and-regression-trees-carts"><i class="fa fa-check"></i><b>5.4.1</b> Classification and regression trees (CARTs)</a></li>
<li class="chapter" data-level="5.4.2" data-path="machine-learning-and-classification.html"><a href="machine-learning-and-classification.html#random-forests"><i class="fa fa-check"></i><b>5.4.2</b> Random Forests</a></li>
<li class="chapter" data-level="5.4.3" data-path="machine-learning-and-classification.html"><a href="machine-learning-and-classification.html#examples-of-tree-based-methods-used-for-classification"><i class="fa fa-check"></i><b>5.4.3</b> Examples of tree-based methods used for classification</a></li>
<li class="chapter" data-level="5.4.4" data-path="machine-learning-and-classification.html"><a href="machine-learning-and-classification.html#r-functions-1"><i class="fa fa-check"></i><b>5.4.4</b> R functions</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="machine-learning-and-classification.html"><a href="machine-learning-and-classification.html#artificial-neural-networks-ann"><i class="fa fa-check"></i><b>5.5</b> Artificial Neural Networks (ANN)</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="machine-learning-and-classification.html"><a href="machine-learning-and-classification.html#ann-learning"><i class="fa fa-check"></i><b>5.5.1</b> ANN learning</a></li>
<li class="chapter" data-level="5.5.2" data-path="machine-learning-and-classification.html"><a href="machine-learning-and-classification.html#our-first-ann"><i class="fa fa-check"></i><b>5.5.2</b> Our first ANN</a></li>
<li class="chapter" data-level="5.5.3" data-path="machine-learning-and-classification.html"><a href="machine-learning-and-classification.html#examples-of-anns-used-for-classification"><i class="fa fa-check"></i><b>5.5.3</b> Examples of ANNs used for classification</a></li>
<li class="chapter" data-level="5.5.4" data-path="machine-learning-and-classification.html"><a href="machine-learning-and-classification.html#r-functions-2"><i class="fa fa-check"></i><b>5.5.4</b> R functions</a></li>
<li class="chapter" data-level="5.5.5" data-path="machine-learning-and-classification.html"><a href="machine-learning-and-classification.html#what-else"><i class="fa fa-check"></i><b>5.5.5</b> What else?</a></li>
<li class="chapter" data-level="5.5.6" data-path="machine-learning-and-classification.html"><a href="machine-learning-and-classification.html#feedback-4"><i class="fa fa-check"></i><b>5.5.6</b> Feedback</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="machine-learning-and-classification.html"><a href="machine-learning-and-classification.html#references-1"><i class="fa fa-check"></i><b>5.6</b> References</a></li>
<li class="chapter" data-level="5.7" data-path="machine-learning-and-classification.html"><a href="machine-learning-and-classification.html#answer-key-1"><i class="fa fa-check"></i><b>5.7</b> Answer Key</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="optimization.html"><a href="optimization.html"><i class="fa fa-check"></i><b>6</b> Optimization</a>
<ul>
<li class="chapter" data-level="6.1" data-path="optimization.html"><a href="optimization.html#introduction"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="optimization.html"><a href="optimization.html#fundamentals-of-optimization"><i class="fa fa-check"></i><b>6.2</b> Fundamentals of Optimization</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="optimization.html"><a href="optimization.html#fermats-theorem"><i class="fa fa-check"></i><b>6.2.1</b> Fermat’s Theorem</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="optimization.html"><a href="optimization.html#regression"><i class="fa fa-check"></i><b>6.3</b> Regression</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="optimization.html"><a href="optimization.html#linear-regression"><i class="fa fa-check"></i><b>6.3.1</b> Linear Regression</a></li>
<li class="chapter" data-level="6.3.2" data-path="optimization.html"><a href="optimization.html#nonlinear-regression"><i class="fa fa-check"></i><b>6.3.2</b> Nonlinear Regression</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="optimization.html"><a href="optimization.html#iterative-optimization-algorithms"><i class="fa fa-check"></i><b>6.4</b> Iterative Optimization Algorithms</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="optimization.html"><a href="optimization.html#gradient"><i class="fa fa-check"></i><b>6.4.1</b> Gradient Descent</a></li>
<li class="chapter" data-level="6.4.2" data-path="optimization.html"><a href="optimization.html#global-optimization"><i class="fa fa-check"></i><b>6.4.2</b> Global Optimization</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="optimization.html"><a href="optimization.html#calibration-of-dynamic-models"><i class="fa fa-check"></i><b>6.5</b> Calibration of Dynamic Models</a></li>
<li class="chapter" data-level="6.6" data-path="optimization.html"><a href="optimization.html#uncertainty-analysis-and-bayesian-calibration"><i class="fa fa-check"></i><b>6.6</b> Uncertainty Analysis and Bayesian Calibration</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="optimization.html"><a href="optimization.html#feedback-5"><i class="fa fa-check"></i><b>6.6.1</b> Feedback</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="optimization.html"><a href="optimization.html#references-2"><i class="fa fa-check"></i><b>6.7</b> References</a></li>
<li class="chapter" data-level="6.8" data-path="optimization.html"><a href="optimization.html#answer-key-2"><i class="fa fa-check"></i><b>6.8</b> Answer Key</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="optimization.html"><a href="optimization.html#exercise-1-2"><i class="fa fa-check"></i><b>6.8.1</b> Exercise 1</a></li>
<li class="chapter" data-level="6.8.2" data-path="optimization.html"><a href="optimization.html#solution"><i class="fa fa-check"></i><b>6.8.2</b> Solution</a></li>
<li class="chapter" data-level="6.8.3" data-path="optimization.html"><a href="optimization.html#exercise-2-2"><i class="fa fa-check"></i><b>6.8.3</b> Exercise 2</a></li>
<li class="chapter" data-level="6.8.4" data-path="optimization.html"><a href="optimization.html#solution-1"><i class="fa fa-check"></i><b>6.8.4</b> Solution</a></li>
<li class="chapter" data-level="6.8.5" data-path="optimization.html"><a href="optimization.html#exercise-3-1"><i class="fa fa-check"></i><b>6.8.5</b> Exercise 3</a></li>
<li class="chapter" data-level="6.8.6" data-path="optimization.html"><a href="optimization.html#solution-2"><i class="fa fa-check"></i><b>6.8.6</b> Solution</a></li>
<li class="chapter" data-level="6.8.7" data-path="optimization.html"><a href="optimization.html#exercise-4-1"><i class="fa fa-check"></i><b>6.8.7</b> Exercise 4</a></li>
<li class="chapter" data-level="6.8.8" data-path="optimization.html"><a href="optimization.html#solution-3"><i class="fa fa-check"></i><b>6.8.8</b> Solution</a></li>
<li class="chapter" data-level="6.8.9" data-path="optimization.html"><a href="optimization.html#exercise-5-1"><i class="fa fa-check"></i><b>6.8.9</b> Exercise 5</a></li>
<li class="chapter" data-level="6.8.10" data-path="optimization.html"><a href="optimization.html#solution-4"><i class="fa fa-check"></i><b>6.8.10</b> Solution</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Building Skills in Quantitative Biology</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="multi" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Multivariate analysis: Clustering and Ordination</h1>
<p>Imagine you are a public health researcher and you wish to determine how the health of individuals in a population is related to their living and working conditions, and access to health services. You will, of course, have to define health in terms of factors that can be measured for each individual such as: body mass index, mobility, sick days per year, blood pressure, self-reported well-being on a scale of 1 to 5, and so on. One could create a single synthetic “health” metric to which standard univariate approaches, such as multiple linear regression, could be applied. However, it is certainly plausible that different components of this metric could be related to different aspects of the potential predictors. In addition, some of the components of health may not not responsive to the potential predictors. It may be better to explore how all the different indicator and predictor variables are related.</p>
<p>Similarly, we may wish to understand how precipitation, fertilization application rates, slope, soil composition and compaction are related to plant community composition. In this question, we may be tracking the abundance of over a dozen different species and many different sites with different types of soil, precipitation and other environmental factors. Again, we could possibly convert this multiplicity of information so that we have a single metric to describe the plant community (e.g., biodiversity), but such conversion may obscure important differences between species. Again, you can easily see that this is not a situation that ordinary univariate approaches are designed to handle!</p>
<p>In this module we’ll be discussing multivariate quantitative methods. Analyses such as linear regression, where we relate a response, <em>y</em>, to a predictor variable, <em>x</em>, are univariate techniques. If we have multiple responses, <span class="math inline">\(y_1...y_n\)</span>, and multiple predictors, <span class="math inline">\(x_1...x_n\)</span>, we need multivariate approaches. There are many types of multivariate analysis, and we will only describe some of the most common ones. We can think of these different types of analysis as laying at different ends of a spectrum of treating the data as discrete vs continuous, and relying on identifying a reponse variable <em>a priori</em> versus letting the “data tell us” about explanatory features, i.e., latent variables (Fig. <a href="multi.html#fig:f1">4.1</a>).</p>
<p><br>
<br></p>
<div class="figure"><span id="fig:f1"></span>
<img src="_main_files/figure-html/f1-1.png" alt="A 4 quadrant plane with y-axis 'response variable' and 'latent variable' and x-axis 'Continuous' and 'Discrete'. There are four quadrants 'Regression', 'Ordination', 'Classification', and 'Clustering' labelled counterclockwise from the top left." width="576" />
<p class="caption">
Figure 4.1: Types of multivariate analysis
</p>
</div>
<p><br></p>
<div id="multivariate-resemblance" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Multivariate resemblance</h2>
<p>The starting point for a lot of the classic multivariate methods is to find metrics that describe how similar two individuals, samples, sites or species might be. A natural way to quantify similarity is to list those characters that are shared. For example, what genetic or morphological features are the same or different between two species? A <strong>resemblance measure</strong> quantifies similarity by adding up in some way the similarities and differences between two things. We can express the shared characters of objects as either:
<strong>similarity (S)</strong>, which quantifies the degree of resemblance or <strong>dissimilarity (D)</strong>, which quantifies the degree of difference.</p>
<div id="binary-similarity-metrics" class="section level3" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> Binary Similarity metrics</h3>
<p>The simplest similarity metric just tallys the number of shared features. This is called a binary similarity metric, since we are just indicating a yes or no for each characteristic of the two things we wish to compare (Table <a href="multi.html#tab:t1">4.1</a>).
<br></p>
<table style="width:65%;">
<caption>
<span id="tab:t1">Table 4.1: </span>List of shared attributes for two things
</caption>
<thead>
<tr>
<th style="text-align:center;">
Attribute
</th>
<th style="text-align:center;">
Object 1
</th>
<th style="text-align:center;">
Object 2
</th>
<th style="text-align:center;">
Similar
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Attribute 1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
no
</td>
</tr>
<tr>
<td style="text-align:center;">
Attribute 2
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
no
</td>
</tr>
<tr>
<td style="text-align:center;">
Attribute 3
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
yes
</td>
</tr>
<tr>
<td style="text-align:center;">
Attribute 4
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
yes
</td>
</tr>
<tr>
<td style="text-align:center;">
Attribute 5
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
yes
</td>
</tr>
<tr>
<td style="text-align:center;">
Attribute 6
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
yes
</td>
</tr>
<tr>
<td style="text-align:center;">
Attribute 7
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
no
</td>
</tr>
<tr>
<td style="text-align:center;">
Attribute 8
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
yes
</td>
</tr>
<tr>
<td style="text-align:center;">
Attribute 9
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
yes
</td>
</tr>
<tr>
<td style="text-align:center;">
Attribute 10
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
no
</td>
</tr>
</tbody>
</table>
<p><br>
We could also use a shared <em>lack</em> of features as an indicator of similarity. The simple matching coefficient uses both shared features, and shared absent features, to quantify similarity as <span class="math inline">\(S_m=\frac{a+d}{a+b+c+d}\)</span>, where <em>a</em> refers to the number of shared characteristics of object 1 and object 2, <em>b</em> is the number characteristics that object 1 possesses but object 2 does not and so on (see Table <a href="multi.html#tab:t2">4.2</a>).
<br>
<br></p>
<table style="width:90%; width: auto !important; " class="table table-bordered">
<caption>
<span id="tab:t2">Table 4.2: </span>Summary of shared and absent attributes
</caption>
<thead>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="1">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Object 1
</div>
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="1">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Object 2
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
Present
</th>
<th style="text-align:center;">
Absent
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;font-weight: bold;">
Object 1
</td>
<td style="text-align:center;font-weight: bold;">
Present
</td>
<td style="text-align:center;">
a
</td>
<td style="text-align:center;">
b
</td>
</tr>
<tr>
<td style="text-align:center;font-weight: bold;">
Object 2
</td>
<td style="text-align:center;font-weight: bold;">
Absent
</td>
<td style="text-align:center;">
c
</td>
<td style="text-align:center;">
d
</td>
</tr>
</tbody>
</table>
<p>We can further categorize similarity metrics as <strong>symmetric</strong>, where we regard both shared presence and shared absence as evidence of similarity, the simple matching coefficient, <span class="math inline">\(S_m\)</span> would be an example of this, or <strong>asymmetric</strong>, where we regard only shared presence as evidence of similarity (that is, we ignore shared absences). For example, asymmetric measures are most useful in analyzing ecological community data, since it is unlikely to be informative that two temperature zone communities lack tropical data, or that aquatic environments lack terrestrial species.</p>
<p>The Jaccard index is an asymmetric binary similarity coefficient calculated as <span class="math inline">\(S_J=\frac{a}{a+b+c}\)</span>, while the quite similar Sørenson index is given as <span class="math inline">\(S_S=\frac{2a}{2a+b+c}\)</span>, and so gives greater weight to shared similarities. Both metrics range from 0 to 1, where a value of 1 indicates complete similarity. Notice that both metrics exclude cell <span class="math inline">\(d\)</span> - the shared absences.</p>
<p>Let’s try an example. In the 70s, Watson &amp; Carpenter (1974) compared the zooplankton species present in Lake Erie and Lake Ontario. We can use this information to compare how similar the communities in the two lakes were at this time. We can see that they shared a lot of species (Table <a href="multi.html#tab:t3">4.3</a>)!</p>
<table style="width:60%;">
<caption>
<span id="tab:t3">Table 4.3: </span>Species presence and absence in lake Erie and lake Ontario (data from from Watson &amp; Carpenter 1974)
</caption>
<thead>
<tr>
<th style="text-align:center;">
species
</th>
<th style="text-align:center;">
erie
</th>
<th style="text-align:center;">
ontario
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
7
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
8
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
9
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
11
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
12
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
13
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
14
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
15
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
16
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
17
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
18
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
19
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
20
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
21
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
22
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
23
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
24
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>We can calculate the similarity metrics quite easily using the <strong>table()</strong> function, where 1 indicates presence and 0 indicates absence. I have stored the information from Table <a href="multi.html#tab:t3">4.3</a> in the the dataframe <em>lksp</em>. I’m just going grab the presences and absences, since I don’t need the species identifiers for my calculation.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb13-1"><a href="multi.html#cb13-1" aria-hidden="true" tabindex="-1"></a>tlake <span class="ot">=</span> <span class="fu">table</span>(lksp[, <span class="fu">c</span>(<span class="st">&quot;erie&quot;</span>, <span class="st">&quot;ontario&quot;</span>)])</span>
<span id="cb13-2"><a href="multi.html#cb13-2" aria-hidden="true" tabindex="-1"></a>tlake</span></code></pre></div>
<pre class="Rout"><code>    ontario
erie  1  0
   1 18  1
   0  1  4</code></pre>
<div class="sourceCode" id="cb15"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb15-1"><a href="multi.html#cb15-1" aria-hidden="true" tabindex="-1"></a>a <span class="ot">=</span> tlake[<span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb15-2"><a href="multi.html#cb15-2" aria-hidden="true" tabindex="-1"></a>b <span class="ot">=</span> tlake[<span class="dv">1</span>, <span class="dv">2</span>]</span>
<span id="cb15-3"><a href="multi.html#cb15-3" aria-hidden="true" tabindex="-1"></a>c <span class="ot">=</span> tlake[<span class="dv">2</span>, <span class="dv">1</span>]</span>
<span id="cb15-4"><a href="multi.html#cb15-4" aria-hidden="true" tabindex="-1"></a>d <span class="ot">=</span> tlake[<span class="dv">2</span>, <span class="dv">2</span>]</span>
<span id="cb15-5"><a href="multi.html#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="multi.html#cb15-6" aria-hidden="true" tabindex="-1"></a>S_j <span class="ot">=</span> a<span class="sc">/</span>(a <span class="sc">+</span> b <span class="sc">+</span> c)</span>
<span id="cb15-7"><a href="multi.html#cb15-7" aria-hidden="true" tabindex="-1"></a>S_j</span></code></pre></div>
<pre class="Rout"><code>[1] 0.9</code></pre>
<div class="sourceCode" id="cb17"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb17-1"><a href="multi.html#cb17-1" aria-hidden="true" tabindex="-1"></a>S_s <span class="ot">=</span> <span class="dv">2</span> <span class="sc">*</span> a<span class="sc">/</span>(<span class="dv">2</span> <span class="sc">*</span> a <span class="sc">+</span> b <span class="sc">+</span> c)</span>
<span id="cb17-2"><a href="multi.html#cb17-2" aria-hidden="true" tabindex="-1"></a>S_s</span></code></pre></div>
<pre class="Rout"><code>[1] 0.95</code></pre>
<p>A final note: when a dissimilarity or similarity metric has a finite range, we can simply convert from one to the other. For example, for similarities that range from 1 (identical) to 0 (completely different), dissimilarity would simply be 1-similarity.</p>
</div>
<div id="quantitative-similarity-dissimilarity-metrics" class="section level3" number="4.1.2">
<h3><span class="header-section-number">4.1.2</span> Quantitative similarity &amp; dissimilarity metrics</h3>
<p>While binary similarity metrics are easy to understand, there are a few problems. These metrics work best when we have a small number of characteristics and we have sampled very well (e.g., the zooplankton in Lake Erie and Ontario). However, these metrics are biased against maximum similarity values when we have lots of characteristics (or species) and poor sampling.</p>
<p>In addition, we sometimes have more information than just a “yes” or “no” which we could use to further characterize similarity. Quantitative similarity and dissimilarity metrics make use of this information. Some examples of quantitative similarity metrics are: Percentage similarity (Renkonen index), Morisita’s index of similarity (not dispersion) and Horn’s index. However, quantitative dissimilarity metrics are perhaps more commonly used. In this case, we often talk about the “distance” between two things. Distances are of two types, either dissimilarity, converted from analogous similarity indices, or specific distance measures, such as Euclidean distance, which doesn’t have a counterpart in any similarity index. There are many, many such metrics, and obviously, you should choose the most accurate and meaningful distance measure for a given application. Legendre &amp; Legendre (2012) offer a key on how to select an appropriate measure for given data and problem (check their Tables 7.4-7.6). If you are uncertain, then choose several distance measures and compare the results.</p>
<div id="euclidean-distance" class="section level4" number="4.1.2.1">
<h4><span class="header-section-number">4.1.2.1</span> Euclidean Distance</h4>
<p>Perhaps the mostly commonly used, and easiest to understand distance measure is Euclidean distance. This metric is zero for identical sampling units and has no fixed upper bound.</p>
Euclidean distance in multivariate space is derived from our understanding of distance in a Cartesian plane. If we had two species abundances measured in two different samples, we could then plot the abundance of species 1 and species 2 for each sample on a 2D plane, and draw a line between them. This would be our Euclidean distance: the shortest path between the two points (Fig. <a href="multi.html#fig:f2">4.2</a>).
<div class="figure"><span id="fig:f2"></span>
<img src="_main_files/figure-html/f2-1.png" alt="A plot with x-axis 'Species 1' and y-axis 'Species 2'. A descending linear line connects two blue points title 'sample j' and 'sample k' which are connected by dotted vertical and horizontal lines titled 'b' and 'a'." width="672" />
<p class="caption">
Figure 4.2: Example of a Euclidean distance calculation in a two dimensional space of species abundance
</p>
</div>
<p>We know that to calculate this distance we would just use the Pythagorean theorem as <span class="math inline">\(c=\sqrt{a^2+b^2}\)</span>. To generalize to <span class="math inline">\(n\)</span> species we can say <span class="math inline">\(D^E_{jk}=\sqrt{\sum^n_{i=1}(X_{ij}-X_{ik})^2}\)</span>, where Euclidean distance between samples <em>j</em> and <em>k</em>, <span class="math inline">\(D^E_{jk}\)</span>, is calculated by summing over the distance in abundance of each of n species in the two samples.</p>
<p>Let’s try an example. Given the species abundances in Table <a href="multi.html#tab:t4">4.4</a>, we can calculate the squared difference in abundance for each species, and sum that quantity.</p>
<table style="width:65%;">
<caption>
<span id="tab:t4">Table 4.4: </span>Species abundance and distance calculations for two samples
</caption>
<thead>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
sample j
</th>
<th style="text-align:center;">
sample k
</th>
<th style="text-align:center;">
<span class="math inline">\((X_j-X_k)^2\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Species 1
</td>
<td style="text-align:center;">
19
</td>
<td style="text-align:center;">
35
</td>
<td style="text-align:center;">
256
</td>
</tr>
<tr>
<td style="text-align:center;">
Species 2
</td>
<td style="text-align:center;">
35
</td>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
625
</td>
</tr>
<tr>
<td style="text-align:center;">
Species 3
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
Species 4
</td>
<td style="text-align:center;">
35
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
900
</td>
</tr>
<tr>
<td style="text-align:center;">
Species 5
</td>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
50
</td>
<td style="text-align:center;">
1600
</td>
</tr>
<tr>
<td style="text-align:center;">
Species 6
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
Species 7
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
9
</td>
</tr>
<tr>
<td style="text-align:center;">
Species 8
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
Species 9
</td>
<td style="text-align:center;">
30
</td>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
400
</td>
</tr>
<tr>
<td style="text-align:center;">
Species 10
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
4
</td>
</tr>
<tr>
<td style="text-align:center;">
TOTAL
</td>
<td style="text-align:center;">
131
</td>
<td style="text-align:center;">
113
</td>
<td style="text-align:center;">
3794
</td>
</tr>
</tbody>
</table>
<p><strong>Exercise 1</strong>
Finish the calculation of the Euclidean distance for this data.</p>
<p>Of course, R makes this much easier, I can calculate Euclidean distance using the <strong>dist()</strong> function, after creating a matrix of the two rows of species abundance data from my original <em>eu</em> dataframe.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb19-1"><a href="multi.html#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dist</span>(<span class="fu">rbind</span>(eu<span class="sc">$</span>j, eu<span class="sc">$</span>k), <span class="at">method =</span> <span class="st">&quot;euclidean&quot;</span>)</span></code></pre></div>
<p>There are many other quantitative dissimilarity metrics. For example, Bray Curtis dissimilarity is frequently used by ecologists to quantify differences between samples based on abundance or count data. This measure is usually applied to raw abundance data, but can be applied to relative abundances. It is calculated as: <span class="math inline">\(BC_{ij}=1-\frac{C_{ij}}{S_{i}+S_{j}}\)</span>, where <span class="math inline">\(C_{ij}\)</span> is the sum over the smallest values for only those species in common between both sites, <span class="math inline">\(S_{i}\)</span> and <span class="math inline">\(S_{j}\)</span> are the sum of abundances at the two sites. This metric is directly related to the Sørenson binary similarity metric, and ranges from 0 to 1, with 0 indicating complete similarity. This is not at distance metric, and so, is not appropriate for some types of analysis.</p>
</div>
</div>
<div id="comparing-more-than-two-communitiessamplessitesgenesspecies" class="section level3" number="4.1.3">
<h3><span class="header-section-number">4.1.3</span> Comparing more than two communities/samples/sites/genes/species</h3>
<p>What about the situation where we want to compare more than two communities, species, samples or genes? We can simply generate a dissimilarity or similarity <strong>matrix</strong>, where each pairwise comparison is given. In the species composition matrix below (Table <a href="multi.html#tab:t5">4.5</a>), sample A and B do not share any species, while sample A and C share all species but differ in abundances (e.g. species 3 = 1 in sample A and 8 in sample C). The calculation of Euclidean distance using the <strong>dist()</strong> function produces a lower triangular matrix with the pairwise comparisons (I’ve included the distance with the sample itself on the diagonal).</p>
<p>You might notice that the Euclidean distance values suggest that A and B are the most similar! Euclidean distance puts more weight on differences in species abundances than on difference in species presences. As a result, two samples not sharing any species could appear more similar (with lower Euclidean distance) than two samples which share species that largely differ in their abundances.</p>
<table style="width:65%;">
<caption>
<span id="tab:t5">Table 4.5: </span>Species abundance
</caption>
<thead>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
sample A
</th>
<th style="text-align:center;">
sample B
</th>
<th style="text-align:center;">
sample C
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
species 1
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
species 2
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
4
</td>
</tr>
<tr>
<td style="text-align:center;">
species 3
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
8
</td>
</tr>
</tbody>
</table>
<p><br>
<br></p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb20-1"><a href="multi.html#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dist</span>(<span class="fu">t</span>(spmatrix), <span class="at">method =</span> <span class="st">&quot;euclidean&quot;</span>, <span class="at">diag =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre class="Rout"><code>    A   B   C
A 0.0        
B 1.7 0.0    
C 7.6 9.0 0.0</code></pre>
<p>There are other disadvantages as well, and in general, there is simply no perfect metric. For example, you may dislike the fact that Euclidean distance also has no upper bound, and so it becomes difficult to understand how similar two things are (i.e., the metric can only be understood in a relative way when comparing many things, Sample A is more similar to sample B than sample C, for example). You could use a Bray-Curtis dissimilarity metric, which is quite easy to interpret, but this metric will also confound differences in species presences and differences in species counts (Greenacre 2017). The best policy is to be aware of the advantages and disadvantages of the metrics you choose, and interpret your analysis in light of this information.</p>
</div>
<div id="r-functions" class="section level3" number="4.1.4">
<h3><span class="header-section-number">4.1.4</span> R functions</h3>
<p>There are a number of functions in R that can be used to calculate similarity and dissimilarity metrics. Since we are usually not just comparing two objects, sites or samples, these functions can help make your calculations much quicker when you are comparing many units.</p>
<p><strong>dist()</strong> (base R, no package needed) offers a number of quantitative distance measures (e.g. Euclidean,Canberra and Manhattan). The result is the distance matrix which gives the dissimilarity of each pair of objects, sites or samples. the matrix is an object of the class dist in R.</p>
<p><strong>vegdist()</strong> (library vegan). The default distance used in this function is Bray-Curtis distance, which is considered more suitable for ecological data.</p>
<p><strong>dsvdis()</strong> (library labdsv) Offers some other indices than vegdist (e.g., ruzicka or Růžička), a quantitative analogue of Jaccard, and Roberts.</p>
<p>For full comparison of dist, vegdist and dsvdis, see <a href="http://ecology.msu.montana.edu/labdsv/R/labs/lab8/lab8.html" class="uri">http://ecology.msu.montana.edu/labdsv/R/labs/lab8/lab8.html</a>.</p>
<p><strong>daisy()</strong> (library cluster) Offers Euclidean, Manhattan and Gower distance.</p>
<p><strong>designdist()</strong> (library vegan) Allows one to design virtually any distance measure using the formula for their calculation.</p>
<p><strong>dist.ldc()</strong> (library adespatial) Includes 21 dissimilarity indices described in Legendre &amp; De Cáceres (2013), twelve of which are not readily available in other packages. Note that Bray-Curtis dissimilarity is called percentage difference (method = “percentdiff”).</p>
<p><strong>distance()</strong> (library ecodist) Contains seven distance measures, but the function is more for demonstration (for larger matrices, the calculation takes rather long).</p>
</div>
</div>
<div id="cluster-analysis" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Cluster Analysis</h2>
<p>When we have a large number of things to compare, an examination of a matrix of similarity or dissimilarity metrics can be tedious or even impossible to do. One way to visualize the similarity among units is to use some form of cluster analysis. Clustering is the grouping of data objects into discrete similarity categories according to a defined similarity or dissimilarity measure.</p>
<p>We can contrast clustering, which assumes that units (e.g., sites, communities, species or genes) can be grouped into discrete categories based on similarity, with ordination, which treats the similarity between units as a continuous gradient (we’ll discuss ordination in section <a href="multi.html#Ord">4.3</a>). We can use clustering to do things like discern whether there are one or two or three different communities in three or four or five sampling units. It is used in many fields, such as machine learning, data mining, pattern recognition, image analysis, genomics, systems biology, etc. Machine learning typically regards data clustering as a form of unsupervised learning, or from our figure above (Fig <a href="multi.html#fig:f1">4.1</a>), as a technique that uses “latent” variables because we are not guided by <em>a priori</em> ideas of which variables or samples belong in which clusters.</p>
<div id="hierarchical-clustering-groups-are-nested-within-other-groups." class="section level3" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Hierarchical clustering: groups are nested within other groups.</h3>
<p>Perhaps the most familiar type of clustering is hierarchical. There are two kinds of hierarchical clustering: <strong>divisive</strong> and <strong>agglomerative</strong>. In the divisive method, the entire set of units is divided into smaller and smaller groups. The agglomerative method starts with small groups of few units, and groups them into larger and larger clusters, until the entire data set is sampled (Pielou, 1984). Of course, once you have more than two units, you need some way to assess similarity between the clusters. There are a couple of different methods here. Single linkage assigns the similarity between clusters to the most similar units in each cluster. Complete linkage uses the similarity between the most dissimilar units in each cluster, while average linkage averages over all the units in each cluster (Fig. <a href="multi.html#fig:f6">4.3</a>).</p>
<div class="figure"><span id="fig:f6"></span>
<img src="_main_files/figure-html/f6-1.png" alt="Six ovals arranged in three rows and two columns labelled 'Simple Linkage', 'Complete Linkage', and 'Average Linkage'. Each contain three dots with the first and second connecting a single dot from each oval with a line and the third row connecting all dots in each oval with many lines." width="768" />
<p class="caption">
Figure 4.3: Different methods of determining similarity between clusters
</p>
</div>
<div id="single-linkage-cluster-analysis" class="section level4" number="4.2.1.1">
<h4><span class="header-section-number">4.2.1.1</span> Single Linkage Cluster Analysis</h4>
<p>Single linkage cluster analysis is one of the easiest to explain. It is hierarchical, agglomerative technique. We start by creating a matrix of similarity (or dissimilarity) indices between the units we want to compare.</p>
<p>Then we find the most similar pair of samples, and that will form the 1st cluster. Next, we find either: (a) the second most similar pair of samples or (b) highest similarity between a cluster and a sample, or (c) most similar pair of clusters, whichever is greatest. We then continue this process until until there is one big cluster. Remember that in single linkage, similarity between two clusters = similarity between the two nearest members of the clusters. Or if we are comparing a sample to a cluster, the similarity is defined as the similarity between sample and the nearest member of the cluster.</p>
<p>Let’s try this with simulated data where we have 5 data units (e.g., sites, species, genes), that each have 5 different quantitative characters (e.g., number of individuals of a given species, morphological features, functions).</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb22-1"><a href="multi.html#cb22-1" aria-hidden="true" tabindex="-1"></a>cls <span class="ot">=</span> <span class="fu">data.frame</span>(<span class="at">a =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">34</span>, <span class="dv">1</span>, <span class="dv">12</span>), <span class="at">b =</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">5</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>),</span>
<span id="cb22-2"><a href="multi.html#cb22-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">c =</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">59</span>, <span class="dv">32</span>, <span class="dv">3</span>, <span class="dv">40</span>), <span class="at">d =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">63</span>, <span class="dv">10</span>, <span class="dv">29</span>, <span class="dv">45</span>), <span class="at">e =</span> <span class="fu">c</span>(<span class="dv">44</span>,</span>
<span id="cb22-3"><a href="multi.html#cb22-3" aria-hidden="true" tabindex="-1"></a>        <span class="dv">35</span>, <span class="dv">40</span>, <span class="dv">12</span>, <span class="dv">20</span>))</span>
<span id="cb22-4"><a href="multi.html#cb22-4" aria-hidden="true" tabindex="-1"></a>clsd <span class="ot">=</span> <span class="fu">dist</span>(<span class="fu">t</span>(cls), <span class="at">method =</span> <span class="st">&quot;euclidean&quot;</span>)</span>
<span id="cb22-5"><a href="multi.html#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(clsd, <span class="dv">0</span>)</span></code></pre></div>
<pre class="Rout"><code>   a  b  c  d
b 33         
c 60 71      
d 76 76 36   
e 51 62 48 66</code></pre>
<p>We can see that we construct the cluster diagram by first grouping a and b, followed by c &amp; d, and so on (Fig. <a href="multi.html#fig:clust5">4.4</a>).</p>
<div class="figure"><span id="fig:clust5"></span>
<img src="_main_files/figure-html/clust5-1.png" alt="In panel a) we first group items a and e. In panel b) we group items c and d, and in panel c) we group item e with c and d, and then finally group the a and e cluster with this larger group" width="672" />
<p class="caption">
Figure 4.4: Example of using a dissimilarity matrix to construct a single-linkage cluster diagram. Each panel labelled a), b) and c) shows each successive step in constructing the diagram for items a to e, where numbers indicate the similarity between two items, groups or a group and an item
</p>
</div>
</div>
<div id="how-many-clusters" class="section level4" number="4.2.1.2">
<h4><span class="header-section-number">4.2.1.2</span> How many clusters?</h4>
<p>These hierarchical methods just keep going until all objects are included (agglomerative methods), or are each in their own group (divisive methods). However, neither endpoint is very useful. How do we select the number of groups? There are metrics and techniques to make this decision more objective (see the <a href="https://www.jstatsoft.org/article/view/v061i06">NbClust package</a>). In this brief introduction, we’ll just mention that for hierarchical methods, you can determine the number of groups a given degree of similarity, or set the number of groups and find the degree of similarity that results in that number of groups. Let’s try. We’ll use the <strong>cutree()</strong> function that works on cluster diagrams produced by the <strong>hclust()</strong> function (Fig. <a href="multi.html#fig:hclustfig">4.5</a>).</p>
If we set our dissimilarity threshold at 40, we find that there are three groups: a&amp;b, c&amp;d, and e in its own group.
<div class="figure"><span id="fig:hclustfig"></span>
<img src="_main_files/figure-html/hclustfig-1.png" alt="A dendrogram with y-axis labelled 'Height' and and 5 items labelled 'a' to 'e'. Items a &amp; e are shown linked, as are items c &amp; d, below the cutoff of euclidean distance = 40" width="480" />
<p class="caption">
Figure 4.5: Cluster diagram produced by the function <strong>hclust()</strong> with cut-off line at euclidean distance=40 for group membership
</p>
</div>
<pre class="Rout"><code>a b c d e 
1 1 2 2 3 </code></pre>
</div>
</div>
<div id="partitional-clustering-and-fuzzy-clustering" class="section level3" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> Partitional clustering and Fuzzy clustering</h3>
<p>There are other means of clustering data of course. Partitional clustering is the division of data objects into non-overlapping subsets, such that each data object is in exactly one subset. In one version of this, <strong>k-means clustering</strong>, each cluster is associated with a centroid (center point), and each
data object is assigned to the cluster with the closest centroid. In this method, the number of clusters, K, must be specified in advance. Our method is:</p>
<ol style="list-style-type: decimal">
<li>Choose the number of K clusters</li>
<li>Select K points as the initial centroids</li>
<li>Calculate the distance of all items to the K centroids</li>
<li>Assign items to closest centroid</li>
<li>Recompute the centroid of each cluster</li>
<li>Repeat from (3) until clusters assignments are stable</li>
</ol>
<p>K-means has problems when clusters are of differing sizes and densities, or are non-globular shapes. It is also very sensitive to outliers.</p>
<p>In contrast to strict (or hard) clustering approaches, fuzzy (or soft) clustering methods allow multiple cluster memberships of the clustered items. <strong>Fuzzy clustering</strong> is commonly achieved by assigning to each item a weight of belonging to each cluster. Thus, items at the edge of a cluster may be in a cluster to a lesser degree than items at the center of a cluster. Typically, each item has as many coefficients (weights) as there are clusters that sum up for each item to one.</p>
</div>
<div id="r-functions-for-clustering" class="section level3" number="4.2.3">
<h3><span class="header-section-number">4.2.3</span> R functions for clustering</h3>
<p><strong>hclust()</strong> (base R, no library needed) calculates hierarchical, agglomerative clusters and has its own plot function.</p>
<p><strong>agnes()</strong> (library cluster) Contains six agglomerative algorithms, some not included in hclust.</p>
<p><strong>diana()</strong> divisive hierarchical clustering</p>
<p><strong>kmeans()</strong> kmeans clustering</p>
<p><strong>fanny()</strong>(cluster package) fuzzy clustering</p>
</div>
<div id="example-cluster-analysis-of-isotope-data" class="section level3" number="4.2.4">
<h3><span class="header-section-number">4.2.4</span> Example: Cluster analysis of isotope data</h3>
<p>Let’s try some of these methods on some ecological data. Try to work through the exercise semi-independently. Our first step is to download and import the dataset “Dataset_S1.csv” from Perkins et al. 2014 (see url below). This data contains δ15N and δ13C signatures for species from different food webs. Unfortunately, this data is saved in an .xlsx file.</p>
<p>To read data into R one of the easiest options is to use the read.csv() function with the argument on a .csv file. These <strong>C</strong>omma <strong>S</strong>eparated <strong>F</strong>iles are one of your best options for reproducible research. They are human readable and easily handled by almost every type of software. In contrast Microsoft Excel uses a propriatory file format, is not fully backwards compatible, and although widely used, is not human readable. As a result, we need special tools to access this file outside of Microsoft software products</p>
<p>We’ll download the data set using <strong>download.file()</strong>, and read it using the R library <em>openxlsx</em> (see example below). Once you have successfully read your data file into R, take a look at it! Type <em>iso</em> (or whatever you named your data object) to see if the data file was read in properly. Some datasets will be too large for this approach to be useful (the data will scroll right off the page). In that case, there are a number of commands to look at a portion of the dataset. For example, you could use a command like <em>names(iso)</em> or <em>str(iso)</em>.</p>
<p>One of the best things to do is plot the imported data. Of course, this is not always possible with very large datasets, but this set should work.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb25-1"><a href="multi.html#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(openxlsx)</span>
<span id="cb25-2"><a href="multi.html#cb25-2" aria-hidden="true" tabindex="-1"></a>urlj <span class="ot">=</span> <span class="st">&quot;https://doi.org/10.1371/journal.pone.0093281.s001&quot;</span></span>
<span id="cb25-3"><a href="multi.html#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="fu">download.file</span>(urlj, <span class="st">&quot;p.xlsx&quot;</span>, <span class="at">mode =</span> <span class="st">&quot;wb&quot;</span>)</span>
<span id="cb25-4"><a href="multi.html#cb25-4" aria-hidden="true" tabindex="-1"></a>iso <span class="ot">=</span> <span class="fu">read.xlsx</span>(<span class="st">&quot;p.xlsx&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb26"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb26-1"><a href="multi.html#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(iso<span class="sc">$</span>N <span class="sc">~</span> iso<span class="sc">$</span>C, <span class="at">col =</span> <span class="fu">as.numeric</span>(<span class="fu">as.factor</span>(iso<span class="sc">$</span>Food.Chain)),</span>
<span id="cb26-2"><a href="multi.html#cb26-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">35</span>, <span class="dv">0</span>), <span class="at">pch =</span> <span class="fu">as.numeric</span>(<span class="fu">as.factor</span>(iso<span class="sc">$</span>Species)),</span>
<span id="cb26-3"><a href="multi.html#cb26-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="fu">expression</span>(<span class="fu">paste</span>(delta, <span class="st">&quot;13C&quot;</span>)), <span class="at">ylab =</span> <span class="fu">expression</span>(<span class="fu">paste</span>(delta,</span>
<span id="cb26-4"><a href="multi.html#cb26-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;15N&quot;</span>)))</span>
<span id="cb26-5"><a href="multi.html#cb26-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-6"><a href="multi.html#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">legend =</span> <span class="fu">unique</span>(<span class="fu">as.factor</span>(iso<span class="sc">$</span>Food.Chain)),</span>
<span id="cb26-7"><a href="multi.html#cb26-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">pch =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="fu">as.numeric</span>(<span class="fu">unique</span>(<span class="fu">as.factor</span>(iso<span class="sc">$</span>Food.Chain))),</span>
<span id="cb26-8"><a href="multi.html#cb26-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Food chain&quot;</span>)</span>
<span id="cb26-9"><a href="multi.html#cb26-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-10"><a href="multi.html#cb26-10" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;bottomright&quot;</span>, <span class="at">legend =</span> <span class="fu">as.character</span>(<span class="fu">unique</span>(<span class="fu">as.factor</span>(iso<span class="sc">$</span>Species))),</span>
<span id="cb26-11"><a href="multi.html#cb26-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">pch =</span> <span class="fu">as.numeric</span>(<span class="fu">unique</span>(<span class="fu">as.factor</span>(iso<span class="sc">$</span>Species))), <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>,</span>
<span id="cb26-12"><a href="multi.html#cb26-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;Species&quot;</span>)</span></code></pre></div>
<div class="figure"><span id="fig:chkperkins"></span>
<img src="_main_files/figure-html/chkperkins-1.png" alt="Moving from left to right on the x-axis ('d13C') are groupings for foodwebs with plant species dominated by 'Wheat' 'Nettle', 'Wheat.Maize and 'Maize'. Indicated species are 'Plant', 'Aphid', 'Diplazon' and 'Hoverfly'" width="672" />
<p class="caption">
Figure 4.6: Isotope data from Perkins et al (2014), showing the both the food web membership as given by the dominant plants (colour) and species (symbol) of each sample vs the carbon (‘d13C’) and nitrogen (‘d15N’) isotope signature. Higher tropic levels are found closer to the top of the graph, and food webs with more C4 plant metabolism are found more to the right
</p>
</div>
<p>We are going to use this data set to see if a cluster analysis on δ15N and δ13C can identify the foodweb. That is we are going to see if the latent variables identified by our clustering method match up to what we think we know about the data. Our first step is to create a dissimilarity matrix, but even before this, we must select that part of the data that we wish to use, just the δ15N and δ13C data, not the other components of the dataframe for the downloaded data.</p>
<p>In addition, our analysis will be affected by the missing data. So let’s get remove those rows with missing data right now using the <strong>complete.cases()</strong> function. The function returns a value of TRUE for every row in a dataframe that no missing values in any column. So niso=iso[complete.cases(mydata),], will be a new data frame with only complete row entries.</p>
<p>The function <strong>dist()</strong> will generate a matrix of the pairwise Euclidean distances between pairs of observations. Now that you have a dissimilarity matrix, you can complete a cluster analysis. The function <strong>hclust()</strong> will produce a data frame that can be sent to the plot() function to visualize the recommended clustering. The method used to complete the analysis is indicated below the graph. Please adjust the arguments of the function to complete a single linkage analysis (type ?hclust to call the help page for the function and determine the method to do this).</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb27-1"><a href="multi.html#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(iso)</span></code></pre></div>
<pre class="Rout"><code>&#39;data.frame&#39;:   165 obs. of  7 variables:
 $ Replicate      : num  1 2 3 4 5 6 7 8 9 10 ...
 $ Food.Chain     : chr  &quot;Wheat&quot; &quot;Wheat&quot; &quot;Wheat&quot; &quot;Wheat&quot; ...
 $ Species        : chr  &quot;Plant&quot; &quot;Plant&quot; &quot;Plant&quot; &quot;Plant&quot; ...
 $ Tissue         : chr  &quot;Leaf&quot; &quot;Leaf&quot; &quot;Leaf&quot; &quot;Leaf&quot; ...
 $ Lipid.Extracted: chr  &quot;No&quot; &quot;No&quot; &quot;No&quot; &quot;No&quot; ...
 $ C              : num  -30.1 -31.7 -30.1 -30.9 -31 ...
 $ N              : num  -3.47 -2.68 3.42 1.27 6.2 ...</code></pre>
<div class="sourceCode" id="cb29"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb29-1"><a href="multi.html#cb29-1" aria-hidden="true" tabindex="-1"></a>diso <span class="ot">&lt;-</span> <span class="fu">dist</span>((iso[, <span class="fu">c</span>(<span class="st">&quot;C&quot;</span>, <span class="st">&quot;N&quot;</span>)]), <span class="at">method =</span> <span class="st">&quot;euclidean&quot;</span>)</span>
<span id="cb29-2"><a href="multi.html#cb29-2" aria-hidden="true" tabindex="-1"></a>p <span class="ot">=</span> <span class="fu">hclust</span>(diso, <span class="at">method =</span> <span class="st">&quot;single&quot;</span>, )</span>
<span id="cb29-3"><a href="multi.html#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(p, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">main =</span> <span class="st">&quot;&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;&quot;</span>)</span></code></pre></div>
<div class="figure"><span id="fig:perkclust"></span>
<img src="_main_files/figure-html/perkclust-1.png" alt="Y-axis is labelled 'Height'" width="672" />
<p class="caption">
Figure 4.7: A dendrogram of isotope data from Perkins et al. (2014), where links between samples and groups at lower height indicate greater similarity. Note the distance between sample 5 and all other samples
</p>
</div>
<p>When you graph your cluster using plot(), you notice that there are many individual measurements, but there are only a few large groups. Does it look like there is an outlier? If so, you may want to remove this point from the data set, and then rerun the analysis. The row numbers are used as labels by default, so this is easy to do (niso=niso[-5,]).</p>
<p>When you examine the data set, you noted that there are 4 Food.chain designations. We will use the cutree() function to cut our cluster tree to get the desired number of groups (4), and then save the group numbers to a new column in our original dataframe. For example, iso$clust&lt;- cutree(p,4).We can then plot the data using colours and symbols to see how well our cluster analysis matches the original data classification.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb30-1"><a href="multi.html#cb30-1" aria-hidden="true" tabindex="-1"></a>niso <span class="ot">=</span> iso[<span class="fu">complete.cases</span>(iso), ]</span>
<span id="cb30-2"><a href="multi.html#cb30-2" aria-hidden="true" tabindex="-1"></a>niso <span class="ot">=</span> niso[<span class="sc">-</span><span class="dv">5</span>, ]</span>
<span id="cb30-3"><a href="multi.html#cb30-3" aria-hidden="true" tabindex="-1"></a>diso <span class="ot">&lt;-</span> <span class="fu">dist</span>((niso[, <span class="fu">c</span>(<span class="st">&quot;C&quot;</span>, <span class="st">&quot;N&quot;</span>)]), <span class="at">method =</span> <span class="st">&quot;euclidean&quot;</span>)</span>
<span id="cb30-4"><a href="multi.html#cb30-4" aria-hidden="true" tabindex="-1"></a>p <span class="ot">=</span> <span class="fu">hclust</span>(diso, <span class="at">method =</span> <span class="st">&quot;single&quot;</span>)</span>
<span id="cb30-5"><a href="multi.html#cb30-5" aria-hidden="true" tabindex="-1"></a>niso<span class="sc">$</span>clust <span class="ot">&lt;-</span> <span class="fu">cutree</span>(p, <span class="at">k =</span> <span class="dv">4</span>)</span>
<span id="cb30-6"><a href="multi.html#cb30-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-7"><a href="multi.html#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="co"># plotting the data with 4 groups identified by the</span></span>
<span id="cb30-8"><a href="multi.html#cb30-8" aria-hidden="true" tabindex="-1"></a><span class="co"># single-linkage cluster analysis superimposed</span></span>
<span id="cb30-9"><a href="multi.html#cb30-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(niso<span class="sc">$</span>N <span class="sc">~</span> niso<span class="sc">$</span>C, <span class="at">col =</span> <span class="fu">as.numeric</span>(<span class="fu">as.factor</span>(niso<span class="sc">$</span>clust)),</span>
<span id="cb30-10"><a href="multi.html#cb30-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">35</span>, <span class="dv">0</span>), <span class="at">pch =</span> <span class="fu">as.numeric</span>(<span class="fu">as.factor</span>(niso<span class="sc">$</span>Species)),</span>
<span id="cb30-11"><a href="multi.html#cb30-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="fu">expression</span>(<span class="fu">paste</span>(delta, <span class="st">&quot;13C&quot;</span>)), <span class="at">ylab =</span> <span class="fu">expression</span>(<span class="fu">paste</span>(delta,</span>
<span id="cb30-12"><a href="multi.html#cb30-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;15N&quot;</span>)))</span>
<span id="cb30-13"><a href="multi.html#cb30-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-14"><a href="multi.html#cb30-14" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">legend =</span> <span class="fu">unique</span>(<span class="fu">as.factor</span>(niso<span class="sc">$</span>clust)), <span class="at">pch =</span> <span class="dv">1</span>,</span>
<span id="cb30-15"><a href="multi.html#cb30-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">col =</span> <span class="fu">as.numeric</span>(<span class="fu">unique</span>(<span class="fu">as.factor</span>(niso<span class="sc">$</span>clust))), <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>,</span>
<span id="cb30-16"><a href="multi.html#cb30-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;cluster&quot;</span>)</span>
<span id="cb30-17"><a href="multi.html#cb30-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-18"><a href="multi.html#cb30-18" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;bottomright&quot;</span>, <span class="at">legend =</span> <span class="fu">as.character</span>(<span class="fu">unique</span>(<span class="fu">as.factor</span>(niso<span class="sc">$</span>Species))),</span>
<span id="cb30-19"><a href="multi.html#cb30-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">pch =</span> <span class="fu">as.numeric</span>(<span class="fu">unique</span>(<span class="fu">as.factor</span>(niso<span class="sc">$</span>Species))), <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>,</span>
<span id="cb30-20"><a href="multi.html#cb30-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;Species&quot;</span>)</span></code></pre></div>
<div class="figure"><span id="fig:clustdata"></span>
<img src="_main_files/figure-html/clustdata-1.png" alt="This figure has x-axis labelled 'd13C', y-axis labelled 'd15N. There are only two samples indicated as belonging to cluster 3'." width="672" />
<p class="caption">
Figure 4.8: Data from Perkins et al (2014) with grouping from single linkage clustering superimposed with calculated clusters 1 to 4 as well as species categories of ‘Plant,’ ‘Aphid,’ ‘Diplazon’ and ‘Hoverfly’ with varying symbols
</p>
</div>
<p>It doesn’t look like our cluster algorithm is matching up with our Food.chain data categories very well. Wheat- and Nettle-based food chains cannot be distinguished, which makes sense when you consider that both of these plants are terrestrial and use a C3 photosynthesis system. If you are not happy with the success of this clustering algorithm you could try other variants (e.g., “complete” linkage) and a different number of groups.</p>
<p><strong>Exercise 2</strong>
Try a non-hierarchical cluster analysis on the same data to see if it works better. Use the <strong>kmeans()</strong> function, which requires that we select the required number of clusters (4) ahead of time. Once you have your clustering, plot your results.</p>
</div>
</div>
<div id="Ord" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Ordination</h2>
<p>While cluster analysis lets us visualize multivariate data by grouping objects into discrete categories, ordination uses continuous axes to help us accomplish the same task. Physicists grumble if space exceeds four dimensions, while biologists typically grapple with dozens of dimensions. We can “order” this multivariate data to produce a low dimensional picture (i.e., a graph in 1-3 dimensions). Just like cluster analysis, we will use similarity metrics to accomplish this. Also like cluster analysis, simple ordination is not a statistical test: it is a method of visualizing data.</p>
<p>Essentially, we find axes in the data that explain a lot of variation, and rotate so we can use the axes as our dimensions of visual representation (Fig. <a href="multi.html#fig:dummy1">4.9</a>). I’ve left the scatter about the line, but actually each point would have only a location on the synthetic xy axis.</p>
<div class="figure"><span id="fig:dummy1"></span>
<img src="_main_files/figure-html/dummy1-1.png" alt="This figure shows two plots each with green points and a blue line of best fit. The first plot is the original orientation and the second is rotated with the x axis labelled 'xy synthesis'" width="576" />
<p class="caption">
Figure 4.9: Synthetic axis rotation in ordination. We find the axis in 2D that explains most variation, and rotate to give a 1D representation
</p>
</div>
<p>Another way to think about it is that we are going to summarize the raw data, which has many variables, <em>p</em>, by a smaller set of synthetic variables, <em>k</em> (Fig. <a href="multi.html#fig:dimred">4.10</a>). If the ordination is informative, it reduces a large number of original correlated variables to a small number of new uncorrelated variables. But it really is a bit of a balancing act between clarity of representation, ease of understanding, and oversimplification. We will lose information in this data reduction, and if that information is important, then we can make the multivariate data harder to understand! Also note that if the original variables are not correlated, then we won’t gain anything with ordination.</p>
<div class="figure"><span id="fig:dimred"></span>
<img src="_main_files/figure-html/dimred-1.png" alt="This figure shows one wide grid labelled 'A' and one narrow grid labelled 'X'. The wide grid  represents the original data while the narrow grid is the reduced data." width="480" />
<p class="caption">
Figure 4.10: Ordination as data reduction. We summarize data with many observations (n) and variables (p) by a smaller set of derived or synthetic variables (k)
</p>
</div>
<p>There are lots of different ways to perform an ordination, but most methods are based on extracting the eigenvalues of a similarity matrix. The four most commonly used methods are: <em>Principle Component Analysis (PCA)</em>, which is the main eigenvector-based method, <em>Correspondence Analysis (CA)</em> which is used used on frequency data, <em>Principle Coordinate Analysis (PCoA)</em> which works on dissimilarity matrices, and <em>Non Metric Multidimensional Scaling (nMDS)</em> which is not an eigenvector method, instead it represents objects along a predetermined number of axes.
Legendre &amp; Legendre (2012) provide a nice summary of when you can use each method (Table <a href="multi.html#tab:tord">4.6</a>). I would like to reiterate that this is a very basic introduction to these methods, and once you are oriented, I suggest you go in search materials authored by experts like Legendre &amp; Legendre (2012), and related materials for R such as Borcard et al. (2011).</p>
<table>
<caption>
<span id="tab:tord">Table 4.6: </span>Domains of application of ordination methods (adapated from Legendre &amp; Legendre 2012)
</caption>
<thead>
<tr>
<th style="text-align:left;">
Method
</th>
<th style="text-align:left;">
Distance
</th>
<th style="text-align:left;">
Variables
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Principal component analysis (PCA)
</td>
<td style="text-align:left;">
Euclidean
</td>
<td style="text-align:left;">
Quantitative data, but not species community data
</td>
</tr>
<tr>
<td style="text-align:left;">
Correspondence analysis (CA)
</td>
<td style="text-align:left;">
<span class="math inline">\(\chi^2\)</span>
</td>
<td style="text-align:left;">
Non-negative, quantitiative or binary data (e.g., species frequencies or presence/absence data)
</td>
</tr>
<tr>
<td style="text-align:left;">
Principal coordinate analysis (PCoA)
</td>
<td style="text-align:left;">
Any
</td>
<td style="text-align:left;">
Quantitative, semiquantitative, qualitative, or mixed data
</td>
</tr>
<tr>
<td style="text-align:left;">
Nonmetric multidimensional scaling (nMDS)
</td>
<td style="text-align:left;">
Any
</td>
<td style="text-align:left;">
Quantitative, semiquantitative, qualitative, or mixed data
</td>
</tr>
</tbody>
</table>
<div id="PCA" class="section level3" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Principal Components Analysis (PCA)</h3>
<p><strong>P</strong>rincipal <strong>C</strong>omponents <strong>A</strong>nalysis (PCA) is probably the most widely-used and well-known of the standard multivariate methods. It was invented by Pearson (1901) and Hotelling (1933), and first applied in ecology by Goodall (1954) under the name “factor analysis” (NB “principal factor analysis” is also a synonym of PCA). Like most ordination methods, PCA takes a data matrix of <em>n</em> objects by <em>p</em> variables, which may be correlated, and summarizes it by uncorrelated axes (principal components or principal axes) that are linear combinations of the original <em>p</em> variables. The first <em>k</em> components display as much as possible of the variation among objects. PCA uses Euclidean distance calculated from the <em>p</em> variables as the measure of dissimilarity among the <em>n</em> objects, and derives the best possible k-dimensional representation of the Euclidean distances among objects, where <span class="math inline">\(k &lt; p\)</span> .</p>
<p>We can think about this spatially. Objects are represented as a cloud of n points in a multidimensional space with an axis for each of the p variables. So the centroid of the points is defined by the mean of each variable, and
the variance of each variable is the average squared deviation of its n values around the mean of that variable (i.e., <span class="math inline">\(V_i= \frac{1}{n-1}\sum_{m=1}^{n}{(X_{im}-\bar{X_i)}^2}\)</span>). The degree to which the variables are linearly correlated is given by their covariances <span class="math inline">\(C_{ij}=\frac{1}{n-1}\sum_{m=1}^n{(X_{im}-\bar{X_i})(X_{jm}-\bar{X_j})}\)</span>. The objective of PCA is to rigidly rotate the axes of the p-dimensional space to new positions (principal axes) that have the following properties: they are ordered such that principal axis 1 (or the <em>principal component</em> has the highest variance, axis 2 has the next highest variance etc, and the covariance among each pair of principal axes is zero (the principal axes are uncorrelated) (Fig. <a href="multi.html#fig:varord">4.11</a>).</p>
<div class="figure"><span id="fig:varord"></span>
<img src="_main_files/figure-html/varord-1.png" alt="Two overlayed plots with axes as described in the caption, a cluster of points and an upwards trend shown by a dashed line of best fit. There are two guassian curves parallel to each synthetic (Y) axis" width="672" />
<p class="caption">
Figure 4.11: Selecting the synthetic axes in ordination. We have two overlaid plots where those axes labelled X1 and X2 are the original data, and those labelled Y1 and Y2 are our synthetic axis. The two guassian functions suggest how much variation is present on each of the two y synthetic axes.
</p>
</div>
<p>So our steps are to compute the variance-covariance matrix of the data, calculate the eigenvalues of this matrix and then calculate the associated eigenvectors. Then, the jth eigenvalue is the variance of the jth principle component and the sum of all the eigenvalues is the total variance explained. The proportion of variance explained by each component, or synthetic axis, is the eigenvalue for the component divided by the total variance explained, while the rotations are the eigenvectors. Dimensionality reduction is the same as first rotating the data with the eigenvalues to be aligned with the principle components, then display using only the components with the greatest eigenvalues.</p>
<div id="example-pca-on-the-iris-data" class="section level4" number="4.3.1.1">
<h4><span class="header-section-number">4.3.1.1</span> Example: PCA on the iris data</h4>
<p>We’re going to use a sample dataset in R and the base R version of PCA to start exploring this data analysis technique. Get the iris dataset into memory by typing data(“iris”). Take a look at this dataset using the <strong>head()</strong>, <strong>str()</strong> or <strong>summary()</strong> functions. For a multivariate data set, you would also like to take a look at the pairwise correlations. Remember that PCA can’t help us if the variables are not correlated. Let’s use the <strong>pairs()</strong> function to do this</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb31-1"><a href="multi.html#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;iris&quot;</span>)</span>
<span id="cb31-2"><a href="multi.html#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(iris)</span></code></pre></div>
<pre class="Rout"><code>&#39;data.frame&#39;:   150 obs. of  5 variables:
 $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
 $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
 $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
 $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
 $ Species     : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<div class="sourceCode" id="cb33"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb33-1"><a href="multi.html#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(iris[<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span></code></pre></div>
<pre class="Rout"><code>  Sepal.Length  Sepal.Width   Petal.Length  Petal.Width 
 Min.   :4.3   Min.   :2.0   Min.   :1.0   Min.   :0.1  
 1st Qu.:5.1   1st Qu.:2.8   1st Qu.:1.6   1st Qu.:0.3  
 Median :5.8   Median :3.0   Median :4.3   Median :1.3  
 Mean   :5.8   Mean   :3.1   Mean   :3.8   Mean   :1.2  
 3rd Qu.:6.4   3rd Qu.:3.3   3rd Qu.:5.1   3rd Qu.:1.8  
 Max.   :7.9   Max.   :4.4   Max.   :6.9   Max.   :2.5  </code></pre>
<div class="sourceCode" id="cb35"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb35-1"><a href="multi.html#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(iris[<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>], <span class="at">main =</span> <span class="st">&quot;Iris Data&quot;</span>, <span class="at">pch =</span> <span class="fu">as.numeric</span>(iris<span class="sc">$</span>Species) <span class="sc">+</span></span>
<span id="cb35-2"><a href="multi.html#cb35-2" aria-hidden="true" tabindex="-1"></a>    <span class="dv">14</span>, <span class="at">col =</span> <span class="fu">as.numeric</span>(iris<span class="sc">$</span>Species) <span class="sc">+</span> <span class="dv">1</span>)</span></code></pre></div>
<div class="figure"><span id="fig:coriris"></span>
<img src="_main_files/figure-html/coriris-1.png" alt="A total of twelve pairwise correlation plots for the four characteristics in iris dataset: sepal length, sepal width, petal length, and petal width. In each plot, one of the four characterstics is selected as x-axis and y-axis with data points based on species." width="672" />
<p class="caption">
Figure 4.12: Correlation matrix for characteristics of each individual the iris data. Colours give species identity
</p>
</div>
<p>The colours let us see the data for each species, the graph is all the pairwise plots of each pair of the 4 variables (Fig. <a href="multi.html#fig:coriris">4.12</a>). Do you see any correlations?</p>
<p>If there seem to be some correlations we might use PCA to reduce the 4 dimensional variable space to 2 or 3 dimensions. Let’s rush right in and use the <strong>prcomp()</strong> function to run a PCA on the numerical data in the iris dataframe. Save the output from the function to a new variable name so you can look at it when you type that name. The <strong>str()</strong> function will show you what the output object includes. If you use the <strong>summary()</strong> function, R will tell you what proportion of the total variance is explained by each synthetic axis.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb36-1"><a href="multi.html#cb36-1" aria-hidden="true" tabindex="-1"></a>pca <span class="ot">&lt;-</span> <span class="fu">prcomp</span>(iris[, <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span>
<span id="cb36-2"><a href="multi.html#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(pca)</span></code></pre></div>
<pre class="Rout"><code>Importance of components:
                         PC1    PC2    PC3     PC4
Standard deviation     2.056 0.4926 0.2797 0.15439
Proportion of Variance 0.925 0.0531 0.0171 0.00521
Cumulative Proportion  0.925 0.9777 0.9948 1.00000</code></pre>
</div>
<div id="standardize-your-data" class="section level4" number="4.3.1.2">
<h4><span class="header-section-number">4.3.1.2</span> Standardize your data</h4>
<p>There is a problem though, let’s examine the variance in the raw data. Use the <strong>apply()</strong> function to quickly calculate the variance in each of the numeric columns of the data as apply(iris[,1:3], 1, var). What do you see? Are the variances of each the columns comparable?</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb38-1"><a href="multi.html#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">apply</span>(iris[, <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>], <span class="dv">2</span>, var)</span></code></pre></div>
<pre class="Rout"><code>Sepal.Length  Sepal.Width Petal.Length  Petal.Width 
        0.69         0.19         3.12         0.58 </code></pre>
<p>Using covariances among variables only makes sense if they are measured in the same units, and even then, variables with high variances will dominate the principal components. These problems are generally avoided by standardizing each variable to unit variance and zero mean as <span class="math inline">\(X_{im}^{&#39;}=\frac{x_{im}-\bar{X_i}}{sd_i}\)</span> where <em>sd</em> is the standard deviation of variable <em>i</em>. After standardizaton, the variance of each variable is 1 and the covariances of the standardized variables are correlations.</p>
<p>If you look at the help menu, the notes for the use of <strong>prcomp()</strong> STRONGLY recommend standardizing the data. To do this there is a built in option. We just need to set scale=TRUE. Let’s try again with data standardization. Save your new PCA output to a different name. Take a look at the summary.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb40-1"><a href="multi.html#cb40-1" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">prcomp</span>(iris[, <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>], <span class="at">scale =</span> <span class="cn">TRUE</span>)</span>
<span id="cb40-2"><a href="multi.html#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(p)</span></code></pre></div>
<pre class="Rout"><code>Importance of components:
                        PC1   PC2    PC3     PC4
Standard deviation     1.71 0.956 0.3831 0.14393
Proportion of Variance 0.73 0.229 0.0367 0.00518
Cumulative Proportion  0.73 0.958 0.9948 1.00000</code></pre>
<p>We now have less variance explained by axis 1. This makes sense, because, as we will see in a moment, axis 1 is strongly influenced by petal length, but in the unstandardized data, petal length had larger variance than anything else.</p>
</div>
<div id="choose-your-axes" class="section level4" number="4.3.1.3">
<h4><span class="header-section-number">4.3.1.3</span> Choose your axes</h4>
<p>Now we need to determine how many axes to use to interpret our analysis. For 4 variables it is easy enough to just look that the amount of variance, as we just did. For larger numbers of variables a plot can be useful. The <strong>screeplot()</strong> function will output the variance (called inertia) explained by each of the principle component axes, and you can make a decision based on that.</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb42-1"><a href="multi.html#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">screeplot</span>(p, <span class="at">type =</span> (<span class="st">&quot;lines&quot;</span>), <span class="at">main =</span> <span class="st">&quot;&quot;</span>, <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">cex =</span> <span class="dv">1</span>)</span></code></pre></div>
<div class="figure"><span id="fig:scree"></span>
<img src="_main_files/figure-html/scree-1.png" alt="The relationship between variances and the number of axes that explain the dataset. As the number of axes increases from 1 to 4, the variances decrease from 3 to 0." width="672" />
<p class="caption">
Figure 4.13: Screeplot: a display of the variance explained by each of the principal components (i.e., synthetic axes). The variance explained decreases for each subsequent axis
</p>
</div>
<p>An ideal curve should be steep, then bend at an “elbow” — this is your cutting-off point — and after that flattens out. To deal with a not-so-ideal scree plot curve you can apply the Kaiser rule: pick PCs with eigenvalues of at least 1. Or you can select using the proportion of variance where the PCs should be able to describe at least 80% of the variance.</p>
<p>It looks like synthetic axes 1 &amp; 2 explain most of the variation. This is, of course, always true, but in this case only a very small proportion of the variance is explained by axes 3 &amp; 4, so we don’t need to consider them any further. So let’s plot axes 1 &amp; 2.</p>
</div>
<div id="plot-your-ordination" class="section level4" number="4.3.1.4">
<h4><span class="header-section-number">4.3.1.4</span> Plot your ordination</h4>
<p>A PCA plot displays our samples in terms of their position (or <strong>scores</strong>) on the new axes. We can add information about how much variation each axis explains, and colour our points to match species identity. In this 2D representation of 4 dimensional space, it looks like species <em>I. versicolor</em> and <em>I. viriginica</em> are the most similar (Fig. <a href="multi.html#fig:pacfirst">4.14</a>).</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb43-1"><a href="multi.html#cb43-1" aria-hidden="true" tabindex="-1"></a>pvar <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">summary</span>(p)<span class="sc">$</span>importance[<span class="dv">2</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>], <span class="dv">2</span>)</span>
<span id="cb43-2"><a href="multi.html#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="multi.html#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(p<span class="sc">$</span>x[, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>], <span class="at">col =</span> <span class="fu">as.numeric</span>(iris<span class="sc">$</span>Species) <span class="sc">+</span> <span class="dv">1</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>,</span>
<span id="cb43-4"><a href="multi.html#cb43-4" aria-hidden="true" tabindex="-1"></a>    <span class="dv">3</span>), <span class="at">cex =</span> <span class="dv">1</span>, <span class="at">pch =</span> <span class="fu">as.numeric</span>(iris<span class="sc">$</span>Species) <span class="sc">+</span> <span class="dv">14</span>, <span class="at">xlab =</span> <span class="fu">paste0</span>(<span class="st">&quot;PC1 (&quot;</span>,</span>
<span id="cb43-5"><a href="multi.html#cb43-5" aria-hidden="true" tabindex="-1"></a>    pvar[<span class="dv">1</span>] <span class="sc">*</span> <span class="dv">100</span>, <span class="st">&quot;%)&quot;</span>), <span class="at">ylab =</span> <span class="fu">paste0</span>(<span class="st">&quot;PC2 (&quot;</span>, pvar[<span class="dv">2</span>] <span class="sc">*</span> <span class="dv">100</span>,</span>
<span id="cb43-6"><a href="multi.html#cb43-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;%)&quot;</span>))</span>
<span id="cb43-7"><a href="multi.html#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">legend =</span> <span class="fu">unique</span>(iris<span class="sc">$</span>Species), <span class="at">pch =</span> <span class="fu">as.numeric</span>(<span class="fu">unique</span>(iris<span class="sc">$</span>Species)) <span class="sc">+</span></span>
<span id="cb43-8"><a href="multi.html#cb43-8" aria-hidden="true" tabindex="-1"></a>    <span class="dv">14</span>, <span class="at">col =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>), <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>)</span></code></pre></div>
<div class="figure"><span id="fig:pacfirst"></span>
<img src="_main_files/figure-html/pacfirst-1.png" alt="This figure shows a scatterplot with x-axis labelled 'PC1 (73%)' and y-axis labelled 'PC2 (23%)'. From left to right on the x-axis, the plot shows a cluster of 'setosa' points, 'versicolor' points, to 'virginica' points." width="672" />
<p class="caption">
Figure 4.14: PCA plot for the iris data where distance is related to the similarlity between each sample. Species identity is indicated by colour and symbol shape
</p>
</div>
<p>I’ve plotted the amount of variance explained by each axis, but remember that the 1st axis always explains the most variance. Your interpretation of the ordination plot hould reflect this fact</p>
<p>We can also plot information about influence the various characteristics are having on each of the axes. The eigenvectors used for the rotation give us this information. So let’s just print that out.</p>
<table style="width:50%;">
<caption>
<span id="tab:barload">Table 4.7: </span>Eigenvectors for each variable and synthetic axis
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
PC1
</th>
<th style="text-align:center;">
PC2
</th>
<th style="text-align:center;">
PC3
</th>
<th style="text-align:center;">
PC4
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Sepal.Length
</td>
<td style="text-align:center;">
0.52
</td>
<td style="text-align:center;">
-0.38
</td>
<td style="text-align:center;">
0.72
</td>
<td style="text-align:center;">
0.26
</td>
</tr>
<tr>
<td style="text-align:left;">
Sepal.Width
</td>
<td style="text-align:center;">
-0.27
</td>
<td style="text-align:center;">
-0.92
</td>
<td style="text-align:center;">
-0.24
</td>
<td style="text-align:center;">
-0.12
</td>
</tr>
<tr>
<td style="text-align:left;">
Petal.Length
</td>
<td style="text-align:center;">
0.58
</td>
<td style="text-align:center;">
-0.02
</td>
<td style="text-align:center;">
-0.14
</td>
<td style="text-align:center;">
-0.80
</td>
</tr>
<tr>
<td style="text-align:left;">
Petal.Width
</td>
<td style="text-align:center;">
0.56
</td>
<td style="text-align:center;">
-0.07
</td>
<td style="text-align:center;">
-0.63
</td>
<td style="text-align:center;">
0.52
</td>
</tr>
</tbody>
</table>
<p><br>
<br>
We can see that a lot of information is coming from the petal variables for PC1, but less from the sepal variables (Table <a href="multi.html#tab:barload">4.7</a>). We can plot this out to show how strongly each variable affects each principle component (or synthetic axis).</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb44-1"><a href="multi.html#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="cn">NA</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">4</span>), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">4</span>), <span class="at">xlab =</span> <span class="fu">paste0</span>(<span class="st">&quot;PC1 (&quot;</span>,</span>
<span id="cb44-2"><a href="multi.html#cb44-2" aria-hidden="true" tabindex="-1"></a>    pvar[<span class="dv">1</span>] <span class="sc">*</span> <span class="dv">100</span>, <span class="st">&quot;%)&quot;</span>), <span class="at">ylab =</span> <span class="fu">paste0</span>(<span class="st">&quot;PC2 (&quot;</span>, pvar[<span class="dv">2</span>] <span class="sc">*</span> <span class="dv">100</span>,</span>
<span id="cb44-3"><a href="multi.html#cb44-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;%)&quot;</span>))</span>
<span id="cb44-4"><a href="multi.html#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="st">&quot;grey90&quot;</span>)</span>
<span id="cb44-5"><a href="multi.html#cb44-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="st">&quot;grey90&quot;</span>)</span>
<span id="cb44-6"><a href="multi.html#cb44-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Get co-ordinates of variables (loadings), and multiply by</span></span>
<span id="cb44-7"><a href="multi.html#cb44-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 10</span></span>
<span id="cb44-8"><a href="multi.html#cb44-8" aria-hidden="true" tabindex="-1"></a>l.x <span class="ot">&lt;-</span> p<span class="sc">$</span>rotation[, <span class="dv">1</span>] <span class="sc">*</span> <span class="dv">4</span></span>
<span id="cb44-9"><a href="multi.html#cb44-9" aria-hidden="true" tabindex="-1"></a>l.y <span class="ot">&lt;-</span> p<span class="sc">$</span>rotation[, <span class="dv">2</span>] <span class="sc">*</span> <span class="dv">4</span></span>
<span id="cb44-10"><a href="multi.html#cb44-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw arrows</span></span>
<span id="cb44-11"><a href="multi.html#cb44-11" aria-hidden="true" tabindex="-1"></a><span class="fu">arrows</span>(<span class="at">x0 =</span> <span class="dv">0</span>, <span class="at">x1 =</span> l.x, <span class="at">y0 =</span> <span class="dv">0</span>, <span class="at">y1 =</span> l.y, <span class="at">col =</span> <span class="dv">5</span>, <span class="at">length =</span> <span class="fl">0.15</span>,</span>
<span id="cb44-12"><a href="multi.html#cb44-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">lwd =</span> <span class="fl">1.5</span>)</span>
<span id="cb44-13"><a href="multi.html#cb44-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Label position</span></span>
<span id="cb44-14"><a href="multi.html#cb44-14" aria-hidden="true" tabindex="-1"></a>l.pos <span class="ot">&lt;-</span> l.y  <span class="co"># Create a vector of y axis coordinates</span></span>
<span id="cb44-15"><a href="multi.html#cb44-15" aria-hidden="true" tabindex="-1"></a>lo <span class="ot">&lt;-</span> <span class="fu">which</span>(l.y <span class="sc">&lt;</span> <span class="dv">0</span>)  <span class="co"># Get the variables on the bottom half of the plot</span></span>
<span id="cb44-16"><a href="multi.html#cb44-16" aria-hidden="true" tabindex="-1"></a>hi <span class="ot">&lt;-</span> <span class="fu">which</span>(l.y <span class="sc">&gt;</span> <span class="dv">0</span>)  <span class="co"># Get variables on the top half</span></span>
<span id="cb44-17"><a href="multi.html#cb44-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace values in the vector</span></span>
<span id="cb44-18"><a href="multi.html#cb44-18" aria-hidden="true" tabindex="-1"></a>l.pos <span class="ot">&lt;-</span> <span class="fu">replace</span>(l.pos, lo, <span class="st">&quot;1&quot;</span>)</span>
<span id="cb44-19"><a href="multi.html#cb44-19" aria-hidden="true" tabindex="-1"></a>l.pos <span class="ot">&lt;-</span> <span class="fu">replace</span>(l.pos, hi, <span class="st">&quot;3&quot;</span>)</span>
<span id="cb44-20"><a href="multi.html#cb44-20" aria-hidden="true" tabindex="-1"></a>l.pos[<span class="dv">4</span>] <span class="ot">&lt;-</span> <span class="st">&quot;3&quot;</span></span>
<span id="cb44-21"><a href="multi.html#cb44-21" aria-hidden="true" tabindex="-1"></a>l.x[<span class="dv">3</span><span class="sc">:</span><span class="dv">4</span>] <span class="ot">&lt;-</span> l.x[<span class="dv">3</span><span class="sc">:</span><span class="dv">4</span>] <span class="sc">+</span> <span class="fl">0.75</span></span>
<span id="cb44-22"><a href="multi.html#cb44-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Variable labels</span></span>
<span id="cb44-23"><a href="multi.html#cb44-23" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(l.x, l.y, <span class="at">labels =</span> <span class="fu">row.names</span>(p<span class="sc">$</span>rotation), <span class="at">col =</span> <span class="dv">5</span>, <span class="at">pos =</span> l.pos,</span>
<span id="cb44-24"><a href="multi.html#cb44-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">cex =</span> <span class="dv">1</span>)</span></code></pre></div>
<div class="figure"><span id="fig:loadplot"></span>
<img src="_main_files/figure-html/loadplot-1.png" alt="A plot with x-axis labelled 'PC1 (73%)' and y-axis labelled 'PC2 (23%)'. Four purple arrowed lines labelled 'Sepal.Width', 'Sepal.Length', , 'Petal.Width' and 'Petal.Length' emerge from the center point in various directions" width="672" />
<p class="caption">
Figure 4.15: Contribution of each of the characteristics of the samples to the first two principal component axes
</p>
</div>
<p>We can see that petal width and length are aligned along the PC1 axis, while PC2 explains more variation in sepal width (Fig. <a href="multi.html#fig:loadplot">4.15</a>). That is, petal length and petal width variables are the most important contributors to the first PC. Sepal width variable is the most important contributor to the second PC. To interpret the variable plot remember that positively correlated variables are grouped close together (e.g., petal length and width). Variables with about a 90 angle are probably not correlated (sepal width is not correlated with the other variables), while negatively correlated variables are positioned on opposite sides of the plot origin (~180 angle; opposed quadrants). However, the direction of the axes is arbitrary! The distance between variables and the origin measures the contribution of the variables to the ordination. A shorter arrow indicates its less importance for the ordination. Variables that are away from the origin are well represented. Avoid the mistake of interpreting the relationships among variables based on the proximities of the apices (tips) of the vector arrows instead of their angles.</p>
<p>Another way to portray this information is to create a <strong>biplot</strong> which, in addition to the coordinates of our samples on the synthetic axes PC1 and PC2, also provides information about how the variables align along the synthetic axes. (Fig. <a href="multi.html#fig:pactwo">4.16</a>). According to the plot, <em>I. versicolor</em> and <em>I. virginica</em> have similar petal length and width, but note that the axis direction is arbitrary and coud not be interpreted as suggesting that these two species have longer petal widths than <em>I.setosa</em>.</p>
<p>I have used an arbitrary scaling to display the variable loadings on each axis. Some of the R packages will use a specific scaling that will emphasize particular parts of the plot, either preserving the Euclidean distances between samples or the correlations/covariances between variables (e.g., the vegan package can do this for you, see section <a href="multi.html#tri">4.4.5</a>).</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb45-1"><a href="multi.html#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(p<span class="sc">$</span>x[, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>], <span class="at">pch =</span> <span class="fu">as.numeric</span>(iris<span class="sc">$</span>Species) <span class="sc">+</span> <span class="dv">14</span>, <span class="at">col =</span> <span class="fu">as.numeric</span>(iris<span class="sc">$</span>Species) <span class="sc">+</span></span>
<span id="cb45-2"><a href="multi.html#cb45-2" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">4</span>), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">4</span>), <span class="at">cex =</span> <span class="dv">1</span>, <span class="at">xlab =</span> <span class="fu">paste</span>(<span class="st">&quot;PC1 (&quot;</span>,</span>
<span id="cb45-3"><a href="multi.html#cb45-3" aria-hidden="true" tabindex="-1"></a>    pvar[<span class="dv">1</span>] <span class="sc">*</span> <span class="dv">100</span>, <span class="st">&quot;%)&quot;</span>), <span class="at">ylab =</span> <span class="fu">paste</span>(<span class="st">&quot;PC2 (&quot;</span>, pvar[<span class="dv">2</span>] <span class="sc">*</span> <span class="dv">100</span>,</span>
<span id="cb45-4"><a href="multi.html#cb45-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;%)&quot;</span>))</span>
<span id="cb45-5"><a href="multi.html#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="at">legend =</span> <span class="fu">unique</span>(iris<span class="sc">$</span>Species), <span class="at">pch =</span> <span class="fu">as.numeric</span>(<span class="fu">unique</span>(iris<span class="sc">$</span>Species)) <span class="sc">+</span></span>
<span id="cb45-6"><a href="multi.html#cb45-6" aria-hidden="true" tabindex="-1"></a>    <span class="dv">14</span>, <span class="at">col =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>), <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>)</span>
<span id="cb45-7"><a href="multi.html#cb45-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-8"><a href="multi.html#cb45-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Get co-ordinates of variables (loadings), and multiply by</span></span>
<span id="cb45-9"><a href="multi.html#cb45-9" aria-hidden="true" tabindex="-1"></a><span class="co"># a constant</span></span>
<span id="cb45-10"><a href="multi.html#cb45-10" aria-hidden="true" tabindex="-1"></a>l.x <span class="ot">&lt;-</span> p<span class="sc">$</span>rotation[, <span class="dv">1</span>] <span class="sc">*</span> <span class="dv">4</span></span>
<span id="cb45-11"><a href="multi.html#cb45-11" aria-hidden="true" tabindex="-1"></a>l.y <span class="ot">&lt;-</span> p<span class="sc">$</span>rotation[, <span class="dv">2</span>] <span class="sc">*</span> <span class="dv">4</span></span>
<span id="cb45-12"><a href="multi.html#cb45-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw arrows</span></span>
<span id="cb45-13"><a href="multi.html#cb45-13" aria-hidden="true" tabindex="-1"></a><span class="fu">arrows</span>(<span class="at">x0 =</span> <span class="dv">0</span>, <span class="at">x1 =</span> l.x, <span class="at">y0 =</span> <span class="dv">0</span>, <span class="at">y1 =</span> l.y, <span class="at">col =</span> <span class="dv">5</span>, <span class="at">length =</span> <span class="fl">0.15</span>,</span>
<span id="cb45-14"><a href="multi.html#cb45-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">lwd =</span> <span class="fl">1.5</span>)</span>
<span id="cb45-15"><a href="multi.html#cb45-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Label position</span></span>
<span id="cb45-16"><a href="multi.html#cb45-16" aria-hidden="true" tabindex="-1"></a>l.pos <span class="ot">&lt;-</span> l.y  <span class="co"># Create a vector of y axis coordinates</span></span>
<span id="cb45-17"><a href="multi.html#cb45-17" aria-hidden="true" tabindex="-1"></a>lo <span class="ot">&lt;-</span> <span class="fu">which</span>(l.y <span class="sc">&lt;</span> <span class="dv">0</span>)  <span class="co"># Get the variables on the bottom half of the plot</span></span>
<span id="cb45-18"><a href="multi.html#cb45-18" aria-hidden="true" tabindex="-1"></a>hi <span class="ot">&lt;-</span> <span class="fu">which</span>(l.y <span class="sc">&gt;</span> <span class="dv">0</span>)  <span class="co"># Get variables on the top half</span></span>
<span id="cb45-19"><a href="multi.html#cb45-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace values in the vector</span></span>
<span id="cb45-20"><a href="multi.html#cb45-20" aria-hidden="true" tabindex="-1"></a>l.pos <span class="ot">&lt;-</span> <span class="fu">replace</span>(l.pos, lo, <span class="st">&quot;1&quot;</span>)</span>
<span id="cb45-21"><a href="multi.html#cb45-21" aria-hidden="true" tabindex="-1"></a>l.pos <span class="ot">&lt;-</span> <span class="fu">replace</span>(l.pos, hi, <span class="st">&quot;3&quot;</span>)</span>
<span id="cb45-22"><a href="multi.html#cb45-22" aria-hidden="true" tabindex="-1"></a>l.pos[<span class="dv">4</span>] <span class="ot">&lt;-</span> <span class="st">&quot;3&quot;</span></span>
<span id="cb45-23"><a href="multi.html#cb45-23" aria-hidden="true" tabindex="-1"></a>l.x[<span class="dv">3</span><span class="sc">:</span><span class="dv">4</span>] <span class="ot">&lt;-</span> l.x[<span class="dv">3</span><span class="sc">:</span><span class="dv">4</span>] <span class="sc">+</span> <span class="fl">0.75</span></span>
<span id="cb45-24"><a href="multi.html#cb45-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Variable labels</span></span>
<span id="cb45-25"><a href="multi.html#cb45-25" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(l.x, l.y, <span class="at">labels =</span> <span class="fu">row.names</span>(p<span class="sc">$</span>rotation), <span class="at">col =</span> <span class="dv">5</span>, <span class="at">pos =</span> l.pos,</span>
<span id="cb45-26"><a href="multi.html#cb45-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">cex =</span> <span class="dv">1</span>)</span></code></pre></div>
<div class="figure"><span id="fig:pactwo"></span>
<img src="_main_files/figure-html/pactwo-1.png" alt="A plot with x-axis labelled 'PC1 (73%)' and y-axis labelled 'PC2 (23%)'. Moving from left to right on the x-axis it shows a centered cluster of 'setosa', 'versicolor' to 'virginica' and 4 arrowed lines emerge from the center and pointing in various directions labelled 'Sepal.Width', 'Sepal.Length' 'Petal.Length', and 'Petal.Width'" width="672" />
<p class="caption">
Figure 4.16: PCA biplot for the iris data. This plot combines the vectors that should how the various characteristics of the samples are aligned with the synthetic axes, and the similarity of the the samples as given by their proximity in the ordination space
</p>
</div>
<p>There are some final points to note regarding interpretation. Principal components analysis assumes the relationships among variables are <em>linear</em>, so that the cloud of points in p-dimensional space has linear dimensions that can be effectively summarized by the principal axes. If the structure in the data is nonlinear (i.e., the cloud of points twists and curves its way through p-dimensional space), the principal axes will not be an efficient and informative summary of the data.</p>
<p>For example, in community ecology, we might use PCA to summarize variables whose relationships are approximately linear or at least monotonic (e.g., soil properties might be used to extract a few components that summarize main dimensions of soil variation). However, in general PCA is generally not useful for ordinating community data because relationships among species and environmental factors are highly nonlinear.</p>
<p>This nonlinearity can lead to characteristic artifacts, where, for example, community trends along environmental gradients appear as “horseshoes” in PCA ordinations because of low species density at opposite extremes of an environmental gradiant appear relatively close together in ordination space (i.e., “arch” or “horseshoe” effect).</p>
</div>
<div id="r-functions-for-pca" class="section level4" number="4.3.1.5">
<h4><span class="header-section-number">4.3.1.5</span> R functions for PCA</h4>
<p><strong>prcomp()</strong> (base R, no library needed)</p>
<p><strong>rda()</strong> (vegan)</p>
<p><strong>PCA()</strong> (FactoMineR library)</p>
<p><strong>dudi.pca()</strong> (ade4)</p>
<p><strong>acp()</strong> (amap)</p>
</div>
</div>
<div id="principle-coordinates-analysis-pcoa" class="section level3" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Principle Coordinates Analysis (PCoA)</h3>
<p>The PCoA method may be used with all types of distance descriptors, and so might be able to avoid some problems of PCA. Although, a PCoA computed on a Euclidean distance matrix gives the same results as a PCA conducted on the original data</p>
<div id="r-functions-for-pcoa" class="section level4" number="4.3.2.1">
<h4><span class="header-section-number">4.3.2.1</span> R functions for PCoA</h4>
<p><strong>cmdscale()</strong> (base R, no package needed)</p>
<p><strong>smacofSym()</strong> (library smacof)</p>
<p><strong>pco()</strong>(ecodist)</p>
<p><strong>pco()</strong>(labdsv)</p>
<p><strong>pcoa()</strong>(ape)</p>
<p><strong>dudi.pco()</strong>(ade4)</p>
</div>
</div>
<div id="nonmetric-multidimensional-scaling-nmds" class="section level3" number="4.3.3">
<h3><span class="header-section-number">4.3.3</span> Nonmetric Multidimensional Scaling (nMDS)</h3>
<p>Like PCoA, the method of nonmetric multidimensional scaling (nMDS), produces ordinations of objects from any resemblance matrix. However, nMDS compresses the distances in a non-linear way and its algorithm is computer-intensive, requiring more computing time than PCoA. PCoA is faster for large distance matrices.</p>
<p>This ordination method does not to preserve the exact dissimilarities among objects in an ordination plot, instead it represents as well as possible the ordering relationships among objects in a small and specified number of axes. Like PCoA, nMDS can produce ordinations of objects from any dissimilarity matrix. The method can also cope with missing values, as long as there are enough measures left to position each object with respect to a few others. nMDS is not an eigenvalue technique, and it does not maximize the variability associated with individual axes of the ordination.</p>
<p>In this computational method the steps are:</p>
<ul>
<li><p>Specify the desired number <em>m</em> of axes (dimensions) of the ordination.</p></li>
<li><p>Construct an initial configuration of the objects in the <em>m</em> dimensions, to be used as a starting point of an iterative adjustment process. (tricky: the end result may depend on this. A PCoA ordination may be a good start. Otherwise, try many independent runs with random initial configurations. The package vegan has a function that does this for you)</p></li>
<li><p>Try to position the objects in the requested number of dimensions in such a way as to minimize how far the dissimilarities in the reduced-space configuration are from being monotonic to the original dissimilarities in the association matrix</p></li>
<li><p>The adjustment goes on until the difference between the observed and modelled dissimilarity matrices (called “stress”), can cannot be lowered any further, or until it reaches a predetermined low value (tolerated lack-of-fit).</p></li>
<li><p>Most nMDS programs rotate the final solution using PCA, for easier interpretation.</p></li>
</ul>
<p>We can use a Shephard plot to get information about the distortion of representation. A Shepard diagram compares how far apart your data points are before and after you transform them (ie: goodness-of-fit) as a scatter plot. On the x-axis, we plot the original distances. On the y-axis, we plot the distances output by a dimension reduction algorithm. A really accurate dimension reduction will produce a straight line. However since information is almost always lost during data reduction, at least on real, high-dimension data, so Shepard diagrams rarely look this straight.</p>
<p>Let’s try this for the iris data. We can evaluate the quality of the nMDS solution by checking the Shephard plot.</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb46-1"><a href="multi.html#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(vegan)</span>
<span id="cb46-2"><a href="multi.html#cb46-2" aria-hidden="true" tabindex="-1"></a>nMDS <span class="ot">&lt;-</span> <span class="fu">metaMDS</span>(iris[, <span class="sc">-</span><span class="dv">5</span>], <span class="at">distance =</span> <span class="st">&quot;bray&quot;</span>, <span class="at">k =</span> <span class="dv">2</span>, <span class="at">trace =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<div class="sourceCode" id="cb47"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb47-1"><a href="multi.html#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb47-2"><a href="multi.html#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the stressplot</span></span>
<span id="cb47-3"><a href="multi.html#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="fu">stressplot</span>(nMDS, <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">l.col =</span> <span class="cn">NA</span>, <span class="at">las =</span> <span class="dv">1</span>)</span>
<span id="cb47-4"><a href="multi.html#cb47-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-5"><a href="multi.html#cb47-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the ordination</span></span>
<span id="cb47-6"><a href="multi.html#cb47-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(nMDS<span class="sc">$</span>points, <span class="at">pch =</span> <span class="fu">as.numeric</span>(iris<span class="sc">$</span>Species) <span class="sc">+</span> <span class="dv">14</span>, <span class="at">col =</span> <span class="fu">as.numeric</span>(iris<span class="sc">$</span>Species) <span class="sc">+</span></span>
<span id="cb47-7"><a href="multi.html#cb47-7" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.3</span>, <span class="fl">0.3</span>), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.6</span>, <span class="fl">0.75</span>), <span class="at">cex =</span> <span class="fl">0.7</span>,</span>
<span id="cb47-8"><a href="multi.html#cb47-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">&quot;nMDS1&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;nMDS2&quot;</span>)</span>
<span id="cb47-9"><a href="multi.html#cb47-9" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;bottomleft&quot;</span>, <span class="at">legend =</span> <span class="fu">unique</span>(iris<span class="sc">$</span>Species), <span class="at">pch =</span> <span class="fu">as.numeric</span>(<span class="fu">unique</span>(iris<span class="sc">$</span>Species)) <span class="sc">+</span></span>
<span id="cb47-10"><a href="multi.html#cb47-10" aria-hidden="true" tabindex="-1"></a>    <span class="dv">14</span>, <span class="at">col =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>), <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>, <span class="at">cex =</span> <span class="dv">1</span>)</span>
<span id="cb47-11"><a href="multi.html#cb47-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-12"><a href="multi.html#cb47-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Get co-ordinates of variables, and multiply by scale</span></span>
<span id="cb47-13"><a href="multi.html#cb47-13" aria-hidden="true" tabindex="-1"></a>l.x2 <span class="ot">&lt;-</span> nMDS<span class="sc">$</span>species[<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>] <span class="sc">*</span> <span class="fl">1.25</span></span>
<span id="cb47-14"><a href="multi.html#cb47-14" aria-hidden="true" tabindex="-1"></a>l.y2 <span class="ot">&lt;-</span> nMDS<span class="sc">$</span>species[<span class="sc">-</span><span class="dv">1</span>, <span class="dv">2</span>] <span class="sc">*</span> <span class="fl">1.25</span></span>
<span id="cb47-15"><a href="multi.html#cb47-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-16"><a href="multi.html#cb47-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw arrows</span></span>
<span id="cb47-17"><a href="multi.html#cb47-17" aria-hidden="true" tabindex="-1"></a><span class="fu">arrows</span>(<span class="at">x0 =</span> <span class="dv">0</span>, <span class="at">x1 =</span> l.x2, <span class="at">y0 =</span> <span class="dv">0</span>, <span class="at">y1 =</span> l.y2, <span class="at">col =</span> <span class="dv">5</span>, <span class="at">length =</span> <span class="fl">0.1</span>,</span>
<span id="cb47-18"><a href="multi.html#cb47-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb47-19"><a href="multi.html#cb47-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-20"><a href="multi.html#cb47-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Variable labels</span></span>
<span id="cb47-21"><a href="multi.html#cb47-21" aria-hidden="true" tabindex="-1"></a>l.x1 <span class="ot">&lt;-</span> nMDS<span class="sc">$</span>species[, <span class="dv">1</span>] <span class="sc">*</span> <span class="fl">1.25</span></span>
<span id="cb47-22"><a href="multi.html#cb47-22" aria-hidden="true" tabindex="-1"></a>l.y1 <span class="ot">&lt;-</span> nMDS<span class="sc">$</span>species[, <span class="dv">2</span>] <span class="sc">*</span> <span class="fl">1.25</span></span>
<span id="cb47-23"><a href="multi.html#cb47-23" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(l.x1, l.y1, <span class="at">labels =</span> <span class="fu">row.names</span>(nMDS<span class="sc">$</span>species), <span class="at">col =</span> <span class="dv">1</span>, <span class="at">pos =</span> <span class="dv">3</span>,</span>
<span id="cb47-24"><a href="multi.html#cb47-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">cex =</span> <span class="fl">0.8</span>)</span></code></pre></div>
<div class="figure"><span id="fig:sheptwo"></span>
<img src="_main_files/figure-html/sheptwo-1.png" alt="Two plots: the left plot has x-axis labelled 'Observed Dissimilarity' and a y-axis labelled 'Ordination Distance', with a cluster of points that trend upwards, the right plot has x-axis labelled 'nMDS1' and y-axis labelled 'nMDS2' with three clusters of points and 4 arrows originating from the center" width="768" />
<p class="caption">
Figure 4.17: Shepard’s plot and ordination plot of an nMDS ordination using 2 axes to represent the varespec data in the vegan package
</p>
</div>
<p>In addition to the original dissimilarity and ordination distance, the plot displays two correlation-like statistics on the goodness of fit. The nonmetric fit is given by <span class="math inline">\(R^2\)</span>, while the “linear fit” is the squared correlation between fitted values and ordination distances (Fig. <a href="multi.html#fig:sheptwo">4.17</a> ). There is some deformation here, but in general the representation is really quite good.</p>
<p>nMDS often achieves a less deformed representation of the dissimilarity relationships among objects than a PCoA in the same number of dimensions. But nMDS is a computer-intensive iterative technique exposed to the risk of suboptimum solutions. In comparison, PCoA finds the optimal solution by eigenvalue decomposition.</p>
<div id="r-functions-for-nmds" class="section level4" number="4.3.3.1">
<h4><span class="header-section-number">4.3.3.1</span> R functions for nMDS</h4>
<p><strong>metaMDS()</strong> (vegan package)</p>
<p><strong>isoMDS( )</strong> (MASS)</p>
</div>
</div>
<div id="example-nmds-and-pcoa" class="section level3" number="4.3.4">
<h3><span class="header-section-number">4.3.4</span> Example: nMDS and PCoA</h3>
<p>We are going to use the vegan package, and some built-in data with it to run the nMDS and PcOA. Varespec is a data frame of observations of 44 species of lichen at 24 sites. We’ll calculate both an nMDS and a PCoA using the (<strong>cmdscale()</strong> function) on the Bray-Curtis distance matrix of these data. In each case, we will specify that we want 2 dimensions as our output. The vegan wrapper for nMDS ordination (<strong>metaMDS()</strong>) standardizes our community data by default, using a Wisconsin transform. This is a method of double standardization that avoids negative values in the transformed data, and is completed by first standardizing species data using the maxima, and then the site by totals. We will have to apply this standardization manually for the PCoA analysis, and then calculate the dissimilarity matrix.</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb48-1"><a href="multi.html#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(vegan)</span>
<span id="cb48-2"><a href="multi.html#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(varespec)</span>
<span id="cb48-3"><a href="multi.html#cb48-3" aria-hidden="true" tabindex="-1"></a>nMDS <span class="ot">&lt;-</span> <span class="fu">metaMDS</span>(varespec, <span class="at">trymax =</span> <span class="dv">100</span>, <span class="at">distance =</span> <span class="st">&quot;bray&quot;</span>, <span class="at">k =</span> <span class="dv">2</span>,</span>
<span id="cb48-4"><a href="multi.html#cb48-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">trace =</span> <span class="cn">FALSE</span>)</span>
<span id="cb48-5"><a href="multi.html#cb48-5" aria-hidden="true" tabindex="-1"></a>svarespec <span class="ot">=</span> <span class="fu">wisconsin</span>(varespec)</span>
<span id="cb48-6"><a href="multi.html#cb48-6" aria-hidden="true" tabindex="-1"></a>disimvar <span class="ot">=</span> <span class="fu">vegdist</span>(svarespec, <span class="at">method =</span> <span class="st">&quot;bray&quot;</span>)</span>
<span id="cb48-7"><a href="multi.html#cb48-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-8"><a href="multi.html#cb48-8" aria-hidden="true" tabindex="-1"></a>PCoA <span class="ot">&lt;-</span> <span class="fu">cmdscale</span>(disimvar, <span class="at">k =</span> <span class="dv">2</span>, <span class="at">eig =</span> T, <span class="at">add =</span> T)</span>
<span id="cb48-9"><a href="multi.html#cb48-9" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(PCoA)</span></code></pre></div>
<pre class="Rout"><code>List of 5
 $ points: num [1:24, 1:2] -0.118 -0.103 0.182 0.486 0.106 ...
  ..- attr(*, &quot;dimnames&quot;)=List of 2
  .. ..$ : chr [1:24] &quot;18&quot; &quot;15&quot; &quot;24&quot; &quot;27&quot; ...
  .. ..$ : NULL
 $ eig   : num [1:24] 1.208 0.832 0.743 0.491 0.461 ...
 $ x     : NULL
 $ ac    : num 0.178
 $ GOF   : num [1:2] 0.298 0.298</code></pre>
<p>We’ll plot the PCoA and the nMDS side by side to see if they differ, using the <strong>par(mfrow())</strong> functions. In this case, our species are the variables and our sites are the objects of our attention. For the nMDS it does not make sense to plot the species as vectors, as that implies directionality or increasing abundance, and there is no reason to assume that the abundance will increase linearly in a given direction across the nMDS plot. For this package, the “species score” is calculated as the weighted average of the site scores, where the weights are the abundance of that species at each site. If we look at the object PCoA we see the new 2D coordinates for each site (“points”). These are raw scores, but we can weight them using the in the same way as the nMDS using the <strong>wascores()</strong> function. We can plot the results as plot(PCoA$points). But, since this will be a crowded plot, let’s use a vegan package function <strong>ordipointlabel()</strong> for both instead, which will use an optimization routine to produce the best plot</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb50-1"><a href="multi.html#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb50-2"><a href="multi.html#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ordipointlabel</span>(nMDS, <span class="at">pch =</span> <span class="fu">c</span>(<span class="cn">NA</span>, <span class="cn">NA</span>), <span class="at">cex =</span> <span class="fu">c</span>(<span class="fl">1.2</span>, <span class="fl">0.6</span>), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.6</span>,</span>
<span id="cb50-3"><a href="multi.html#cb50-3" aria-hidden="true" tabindex="-1"></a>    <span class="fl">1.2</span>))</span>
<span id="cb50-4"><a href="multi.html#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="st">&quot;grey&quot;</span>)</span>
<span id="cb50-5"><a href="multi.html#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="st">&quot;grey&quot;</span>)</span>
<span id="cb50-6"><a href="multi.html#cb50-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-7"><a href="multi.html#cb50-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-8"><a href="multi.html#cb50-8" aria-hidden="true" tabindex="-1"></a>PCoA<span class="sc">$</span>species <span class="ot">&lt;-</span> <span class="fu">wascores</span>(PCoA<span class="sc">$</span>points, varespec, <span class="at">expand =</span> <span class="cn">TRUE</span>)</span>
<span id="cb50-9"><a href="multi.html#cb50-9" aria-hidden="true" tabindex="-1"></a><span class="fu">ordipointlabel</span>(PCoA, <span class="at">pch =</span> <span class="fu">c</span>(<span class="cn">NA</span>, <span class="cn">NA</span>), <span class="at">cex =</span> <span class="fu">c</span>(<span class="fl">1.2</span>, <span class="fl">0.6</span>), <span class="at">xlab =</span> <span class="st">&quot;PCoA1&quot;</span>,</span>
<span id="cb50-10"><a href="multi.html#cb50-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylab =</span> <span class="st">&quot;PCoA2&quot;</span>, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.6</span>, <span class="dv">1</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.5</span>, <span class="fl">0.6</span>))</span>
<span id="cb50-11"><a href="multi.html#cb50-11" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="st">&quot;grey&quot;</span>)</span>
<span id="cb50-12"><a href="multi.html#cb50-12" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="st">&quot;grey&quot;</span>)</span></code></pre></div>
<div class="figure"><span id="fig:2panelord"></span>
<img src="_main_files/figure-html/2panelord-1.png" alt="This figure shows two plots, the right plot is titled 'PCoA', has x-axis labelled 'PCoA1' and the left plot is titled 'nMDS', has x-axis labelled 'MDS1' and y-axis labelled 'MDS2'. Each plot contains 24 scattered numbers which represent the sites as well as 44 scattered species names." width="768" />
<p class="caption">
Figure 4.18: Biplots of the lichen data for nMDS and PCoA ordinations
</p>
</div>
<p><strong>Exercise 3</strong>
Provide an interpretation of these plots</p>
</div>
</div>
<div id="constrained-ordination" class="section level2" number="4.4">
<h2><span class="header-section-number">4.4</span> Constrained Ordination</h2>
<p>The patterns we see in the previous exercise are created by differences among thie sites in the relative abundances in species aligned with the major direction of difference (e.g. <em>Betupube</em>). However, biologists often go further than this, and attempt to explain the differences in characteristics (in this case, species abundances) that drives data object differences (in this case, sampling sites) by superimposing relationships of environmental variation associated with the sites in a regression type exercise. This is <strong>constrained</strong> or <strong>canonical ordination</strong></p>
<p>Simple (or unconstrained) ordination is done on one data set, and we try to explain/understand the data by examining a graph constructed with a reduced set of orthogonal axes. The ordination is not influenced by external variables; these may only be considered after we construct the ordination. There is no hypotheses or hypothesis testing: this is an exploratory technique only. In unconstrained ordination axes correspond to the directions of the greatest variability within the data set.</p>
<p>In contrast, constrained ordination associates two or more data sets in the ordination and explicitly explores the relationships between two matrices: a response matrix and an explanatory matrix (Fig <a href="multi.html#fig:ordreg">4.19</a>). Both matrices are used in the production of the ordination. In this method, we can formally test statistical hypotheses about the significance of these relationships. The constrained ordination axes correspond to the directions of the greatest variability of the data set that can be explained by the environmental variables</p>
<div class="figure"><span id="fig:ordreg"></span>
<img src="_main_files/figure-html/ordreg-1.png" alt="Three figures all with the y-axis labelled 'Objects 1 to n'; 'Simple ordination:PCA/CA' has one rectangle named 'matrix Y'. 'Multiple regression' and 'Ordination under constraint: RDA/CCA' both have two retangles connected by a double arrow, the left ones named 'y' and 'matrix Y', and the right ones both named 'matrix X'." width="672" />
<p class="caption">
Figure 4.19: Diagram showing the differences between uncontrained ordination, multiple regression and constrained ordination (adapted from Legendre &amp; Legendre 2012)
</p>
</div>
<p>There are two major methods of constrained commonly used by ecologists. Both combine multiple regression with a standard ordination: <strong>Redundancy analysis (RDA)</strong> and <strong>Canonical correspondence analysis (CCA)</strong>. RDA preserves the Euclidean distances among objects in matrix, which contains values of Y fitted by regression to the explanatory variables X. CCA preserves the <span class="math inline">\(\chi^2\)</span> distance (as in correspondence analysis), instead of the Euclidean distance. The calculations are a bit more complex since the matrix contains fitted values obtained by weighted linear regression of matrix of correspondence analysis on the explanatory variables X</p>
<div id="redundancy-analysis" class="section level3" number="4.4.1">
<h3><span class="header-section-number">4.4.1</span> Redundancy Analysis</h3>
<p>Redundancy analysis was created by Rao (1964) and also independently by Wollenberg (1977).The method seeks, in successive order, linear combinations of the explanatory variables that best explain the variation of the response data. The axes are defined in the space of the explanatory variables that are orthogonal to one another. RDA is therefore a constrained ordination procedure. The difference with unconstrained ordination is important: the matrix of explanatory variables conditions the “weights” (eigenvalues), and the directions of the ordination axes. In RDA, one can truly say that the axes explain or model (in the statistical sense) the variation of the dependent matrix. Furthermore, a global hypothesis (H0) of absence of linear relationship between Y and X can be tested in RDA; this is not the case in PCA.</p>
<p>As in PCA, the variables in Y should be standardized if they are not dimensionally homogeneous (e.g., if they are a mixture of temperatures, concentrations, and pH values), or transformations applicable to community composition data applied if data is species abundance or presence/absence (Legendre &amp; Legendre 2012).</p>
<p>As in multiple regression analysis, matrix X can contain explanatory variables of different mathematical types: quantitative, multistate qualitative (e.g. factors), or binary variables. If present, collinearity among the X variables should be reduced. In cases where several correlated explanatory variables are present, without clear <em>a priori</em> reasons to eliminate one or the other, one can examine the variance inflation factors (VIF) which measure how much the variance of the regression or canonical coefficients is inflated by the presence of correlations among explanatory variables. As a rule of thumb, ter Braak (1988) recommends that variables that have a VIF larger than 20 be removed from the analysis. (Note: always remove the variables one at a time and recompute the analysis, since the VIF of every variable depends on all the others!)</p>
<p>So our steps for an RDA are a combination of the things we would do for a multiple linear regression, and the things we would do for an ordination:</p>
<ol style="list-style-type: decimal">
<li><p>Multivariate linear regression of Y on X: equivalent to regressing each Y response variable on X to calculate vectors of fitted values followed by stacking these column vectors side by side into a new matrix</p></li>
<li><p>Test regression for significance using a permutation test</p></li>
<li><p>If significant, compute a PCA on matrix of fitted values to get the canonical eigenvalues and eigenvectors</p></li>
<li><p>We may also compute the residual values of the multiple regressions and do a PCA on these values</p></li>
</ol>
<div id="r-functions-for-rda" class="section level4" number="4.4.1.1">
<h4><span class="header-section-number">4.4.1.1</span> R functions for RDA</h4>
<p>BEWARE: many things are called rda in R that have nothing to do with ordination!!</p>
<p><strong>rda</strong> (vegan package)- this function calculates RDA if a matrix of environmental variables is supplied (if not, it calculates PCA). Two types of syntax are available: matrix syntax - rda (Y, X, W), where Y is the response matrix (species composition), X is the explanatory matrix (environmental factors) and W is the matrix of covariables, or formula syntax (e.g., RDA = rda (Y ~ var1 + factorA + var2*var3 + Condition (var4), data = XW, where var1 is quantitative, factorA is categorical, there is an interaction term between var2 and var3, while var4 is used as covariable and hence partialled out).</p>
<p>We should mention that there are several closely related forms of RDA analysis:</p>
<p><strong>tb-RDA</strong> (transformation-based RDA, Legendre &amp; Gallagher 2001): transform the species data with vegan’s <strong>decostand()</strong>, then use the transformed data matrix as input matrix Y in RDA.</p>
<p><strong>db-RDA</strong> (distance-based RDA, Legendre &amp; Anderson 1999): compute PCoA from a pre-computed dissimilarity matrix D, then use the principal coordinates as input matrix Y in RDA.</p>
<p><strong>db-RDA</strong> can also be computed directly by function <strong>dbrda()</strong> in vegan. For a Euclidean matrix, the result is the same as if PCoA had been computed, followed by regular RDA. Function dbrda() can directly handle non-Euclidean dissimilarity matrices, but beware of the results if the matrix is strongly non-Euclidean and make certain this is what you want.</p>
<p>Vegan has three methods of constrained ordination: constrained or “canonical” correspondence analysis (<strong>cca()</strong>), redundancy analysis (<strong>rda()</strong>), and distance-based redundancy analysis (<strong>capscale()</strong>). All these functions can have a conditioning term that is “partialled out.” All functions accept similar commands and can be used in the same way. The preferred way is to use formula interface, where the left hand side gives the community data frame and the right hand side lists the constraining variables:</p>
</div>
</div>
<div id="example-constrained-ordination" class="section level3" number="4.4.2">
<h3><span class="header-section-number">4.4.2</span> Example: Constrained ordination</h3>
<p>The rda approach is best for continuous data. Let’s use the lichen data in the vegan package again, with the related environmental variables regarding soil chemistry (varechem).</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb51-1"><a href="multi.html#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(vegan)</span>
<span id="cb51-2"><a href="multi.html#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;varespec&quot;</span>)</span>
<span id="cb51-3"><a href="multi.html#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;varechem&quot;</span>)</span></code></pre></div>
<p>Remember that the environmental data can be inspected using commands <strong>str()</strong> which shows the structure of any object in a compact form, and by asking for a summary of a data frame (e.g., str(varechem) or summary(varechem)). We can also plot the data to get a sense of how correlated the various predictors might be but it is very large for this much data (Fig. <a href="multi.html#fig:lichCOR">4.20</a>)</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb52-1"><a href="multi.html#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(varechem, <span class="at">gap =</span> <span class="dv">0</span>, <span class="at">panel =</span> panel.smooth, <span class="at">cex.lab =</span> <span class="fl">1.2</span>,</span>
<span id="cb52-2"><a href="multi.html#cb52-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">cex =</span> <span class="fl">0.75</span>, <span class="at">col =</span> <span class="fu">rgb</span>(<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.7</span>, <span class="fl">0.8</span>))</span></code></pre></div>
<div class="figure"><span id="fig:lichCOR"></span>
<img src="_main_files/figure-html/lichCOR-1.png" alt="Large plot matrix with pairwise correlations where individual points and overall trend lines are given." width="672" />
<p class="caption">
Figure 4.20: Pairwise correlations between environmental variables in the varechem dataset, where variable name is listed on the diagonal. Chemical measurements are denoted by their chemical element names. ‘Baresoil’ gives the estimated cover of bare soil, ‘Humdepth’ provides the thickness of the humus layer and ‘pH.’
</p>
</div>
<p>We will use a formula interface to constrain the ordination. The shortcut “~.” indicates that we want to use all the variables in the environmental dataset, and you can see this in the output. We will of course remember to standardize and scale our data. The output shows the eigenvalues for both the constrained and unconstrained ordination axes. In particular, see how the variance (inertia) and rank (number of axes) are decomposed in constrained ordination.</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb53-1"><a href="multi.html#cb53-1" aria-hidden="true" tabindex="-1"></a>stvarespec <span class="ot">=</span> <span class="fu">as.data.frame</span>(<span class="fu">wisconsin</span>(varespec))</span>
<span id="cb53-2"><a href="multi.html#cb53-2" aria-hidden="true" tabindex="-1"></a>scvarechem <span class="ot">=</span> <span class="fu">as.data.frame</span>(<span class="fu">scale</span>(varechem))</span>
<span id="cb53-3"><a href="multi.html#cb53-3" aria-hidden="true" tabindex="-1"></a>constr <span class="ot">&lt;-</span> vegan<span class="sc">::</span><span class="fu">rda</span>(stvarespec <span class="sc">~</span> ., <span class="at">data =</span> scvarechem)</span>
<span id="cb53-4"><a href="multi.html#cb53-4" aria-hidden="true" tabindex="-1"></a>constr</span></code></pre></div>
<pre class="Rout"><code>Call: rda(formula = stvarespec ~ N + P + K + Ca + Mg + S + Al + Fe + Mn + Zn +
Mo + Baresoil + Humdepth + pH, data = scvarechem)

              Inertia Proportion Rank
Total          0.0508     1.0000     
Constrained    0.0361     0.7106   14
Unconstrained  0.0147     0.2894    9
Inertia is variance 

Eigenvalues for constrained axes:
   RDA1    RDA2    RDA3    RDA4    RDA5    RDA6    RDA7    RDA8    RDA9   RDA10   RDA11 
0.00812 0.00564 0.00481 0.00353 0.00296 0.00259 0.00195 0.00166 0.00126 0.00113 0.00096 
  RDA12   RDA13   RDA14 
0.00063 0.00051 0.00037 

Eigenvalues for unconstrained axes:
    PC1     PC2     PC3     PC4     PC5     PC6     PC7     PC8     PC9 
0.00405 0.00218 0.00200 0.00185 0.00125 0.00110 0.00102 0.00072 0.00053 </code></pre>
<p>However, it is not recommended to perform a constrained ordination with all the environmental variables you happen to have: adding a large number of constraints means eventually you end up with solution similar to the unconstrained ordination. Moreover, collinearity in the explanatory variables will cause instability in the estimation of regression coefficients (see Fig <a href="multi.html#fig:lichCOR">4.20</a>).</p>
<p>Instead, let’s use the formula interface to select particular constraining variables</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb55-1"><a href="multi.html#cb55-1" aria-hidden="true" tabindex="-1"></a>ord3 <span class="ot">=</span> vegan<span class="sc">::</span><span class="fu">rda</span>(stvarespec <span class="sc">~</span> N <span class="sc">+</span> K <span class="sc">+</span> Al, <span class="at">data =</span> scvarechem)</span>
<span id="cb55-2"><a href="multi.html#cb55-2" aria-hidden="true" tabindex="-1"></a>ord3</span></code></pre></div>
<pre class="Rout"><code>Call: rda(formula = stvarespec ~ N + K + Al, data = scvarechem)

              Inertia Proportion Rank
Total          0.0508     1.0000     
Constrained    0.0117     0.2304    3
Unconstrained  0.0391     0.7696   20
Inertia is variance 

Eigenvalues for constrained axes:
  RDA1   RDA2   RDA3 
0.0067 0.0032 0.0018 

Eigenvalues for unconstrained axes:
   PC1    PC2    PC3    PC4    PC5    PC6    PC7    PC8 
0.0072 0.0041 0.0037 0.0035 0.0033 0.0025 0.0024 0.0018 
(Showing 8 of 20 unconstrained eigenvalues)</code></pre>
<p>Examine the output. How did we do? Unsurprisingly, we have not explained as much variance as the full model. In addition, the amount of variance (inertia) explained by the constrained axes is less than the unconstrained axes. Maybe we shouldn’t be using this analysis at all. Of course, some of the variables in the full model may or may not be important. We need a significance test to try and sort this out.</p>
</div>
<div id="signficance-tests-for-constrained-ordination" class="section level3" number="4.4.3">
<h3><span class="header-section-number">4.4.3</span> Signficance tests for constrained ordination</h3>
<p>The vegan package provides permutation tests for the significance of constraints. The test mimics a standard ANOVA function, and the default test analyses all constraints simultaneously.</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb57-1"><a href="multi.html#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(ord3)</span></code></pre></div>
<pre class="Rout"><code>Permutation test for rda under reduced model
Permutation: free
Number of permutations: 999

Model: rda(formula = stvarespec ~ N + K + Al, data = scvarechem)
         Df Variance  F Pr(&gt;F)    
Model     3   0.0117  2  0.001 ***
Residual 20   0.0391              
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>So the results suggest that our model explains a significant amount of variation in the data. We can also perform significance tests for each variable:</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb59-1"><a href="multi.html#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(ord3, <span class="at">by =</span> <span class="st">&quot;term&quot;</span>, <span class="at">permutations =</span> <span class="dv">199</span>)</span></code></pre></div>
<pre class="Rout"><code>Permutation test for rda under reduced model
Terms added sequentially (first to last)
Permutation: free
Number of permutations: 199

Model: rda(formula = stvarespec ~ N + K + Al, data = scvarechem)
         Df Variance    F Pr(&gt;F)   
N         1   0.0029 1.49  0.085 . 
K         1   0.0031 1.59  0.045 * 
Al        1   0.0057 2.90  0.005 **
Residual 20   0.0391               
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The analysis suggests that maybe we haven’t chosen the best set of predictors. For example, N does not explain a significant amount of variation. This test is sequential: the terms are analyzed in the order they happen to be in the model, so you may get different results depending on how the model is specified. See if you can detect this, by rearranging your model terms in the call to ordination.</p>
<p>NB It is also possible to analyze the significance of marginal effects (“Type III effects”) by specifying that option (by=‘mar’) or analyse the significance of each axis, again by specifying that option in the anova call (i.e.,by=‘axis’).</p>
</div>
<div id="forward-selection-of-explanatory-variables" class="section level3" number="4.4.4">
<h3><span class="header-section-number">4.4.4</span> Forward Selection of explanatory variables</h3>
<p>You may wonder if you have selected the correct variables! We can use the <strong>ordiR2step()</strong> function to perform forward selection (and backwards selection or both directions) on a null model. In automatic model building we usually need two extreme models: the smallest and the largest model considered. First we specify a full model with all the environmental variables, and then a minimal model with intercept only, where both are defined using a formula so that terms can be added or removed from the model. Then we allow an automated model selection function to move between these extremes, trying to minimize a metric of model fit, such as <span class="math inline">\(R^2\)</span>. We will then use ordiR2step() to find an optimal model based on both permutation and adjusted <span class="math inline">\(R^2\)</span> values. If you switch the trace=FALSE option to trace=TRUE you can watch the function doing its work.</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb61-1"><a href="multi.html#cb61-1" aria-hidden="true" tabindex="-1"></a>mfull <span class="ot">&lt;-</span> vegan<span class="sc">::</span><span class="fu">rda</span>(stvarespec <span class="sc">~</span> ., <span class="at">data =</span> scvarechem)</span>
<span id="cb61-2"><a href="multi.html#cb61-2" aria-hidden="true" tabindex="-1"></a>m0 <span class="ot">&lt;-</span> vegan<span class="sc">::</span><span class="fu">rda</span>(stvarespec <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> scvarechem)</span>
<span id="cb61-3"><a href="multi.html#cb61-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-4"><a href="multi.html#cb61-4" aria-hidden="true" tabindex="-1"></a>optm <span class="ot">&lt;-</span> <span class="fu">ordiR2step</span>(m0, <span class="at">scope =</span> <span class="fu">formula</span>(mfull), <span class="at">trace =</span> <span class="cn">FALSE</span>)</span>
<span id="cb61-5"><a href="multi.html#cb61-5" aria-hidden="true" tabindex="-1"></a>optm<span class="sc">$</span>anova</span></code></pre></div>
<pre class="Rout"><code>                R2.adj Df   AIC    F Pr(&gt;F)   
+ Fe            0.0633  1 -71.2 2.55  0.004 **
+ P             0.1036  1 -71.3 1.99  0.008 **
+ Mn            0.1367  1 -71.4 1.81  0.022 * 
&lt;All variables&gt; 0.2604                        
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p><strong>Exercise 4</strong>
Examine the significance test. How does this automatically selected model differ from the full model and your manually selected version?</p>
<p>Next check the variance (i.e., inertia). If the variance explained by the constrained model is not much higher than your unconstrained variance, then it may be that the rda is not really needed. This certainly seems to be the case, but let’s press on regardless!</p>
<pre class="Rout"><code>Call: rda(formula = stvarespec ~ Fe + P + Mn, data = scvarechem)

              Inertia Proportion Rank
Total          0.0508     1.0000     
Constrained    0.0127     0.2493    3
Unconstrained  0.0382     0.7507   20
Inertia is variance 

Eigenvalues for constrained axes:
  RDA1   RDA2   RDA3 
0.0061 0.0036 0.0030 

Eigenvalues for unconstrained axes:
   PC1    PC2    PC3    PC4    PC5    PC6    PC7    PC8 
0.0064 0.0046 0.0038 0.0033 0.0032 0.0026 0.0020 0.0018 
(Showing 8 of 20 unconstrained eigenvalues)</code></pre>
<p>Contrary to what one sometimes reads, variables with high VIFs should generally not be manually removed before the application of a procedure of selection of variables. Indeed, two highly correlated variables that are both strong predictors of one or several of the response variables Y may both contribute significantly, in complementary manners, to the linear model of these response variables. A variable selection procedure is the appropriate way of determining if that is the case.</p>
<p>However, let’s see what happened with collinearity. VIFs can be computed in vegan after RDA or CCA. The algorithm in the <strong>vif.cca()</strong> function allows users to include factors in the RDA; the function will compute VIF after breaking down each factor into dummy variables. If X contains quantitative variables only, the vif.cca() function produces the same result as the normal calculation for quantitative variables.</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb64-1"><a href="multi.html#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="fu">vif.cca</span>(mfull)</span></code></pre></div>
<pre class="Rout"><code>       N        P        K       Ca       Mg        S       Al       Fe       Mn 
     1.9      6.2     11.7      9.8      9.6     18.5     20.3      8.8      5.2 
      Zn       Mo Baresoil Humdepth       pH 
     7.8      4.6      2.2      5.6      6.9 </code></pre>
<div class="sourceCode" id="cb66"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb66-1"><a href="multi.html#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="fu">vif.cca</span>(optm)</span></code></pre></div>
<pre class="Rout"><code> Fe   P  Mn 
1.3 1.4 1.7 </code></pre>
<p>Some VIF values are above 10 or even 20 in the full model, so that a reduction of the number of explanatory variables is justified. The VIF values in the reduced model are quite low.</p>
<p>Finally, let’s examine the adjusted <span class="math inline">\(R^2\)</span> of the full and selected models.</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb68-1"><a href="multi.html#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">RsquareAdj</span>(mfull)<span class="sc">$</span>adj.r.squared, <span class="dv">2</span>)</span></code></pre></div>
<pre class="Rout"><code>[1] 0.26</code></pre>
<div class="sourceCode" id="cb70"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb70-1"><a href="multi.html#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">RsquareAdj</span>(optm)<span class="sc">$</span>adj.r.squared, <span class="dv">2</span>)</span></code></pre></div>
<pre class="Rout"><code>[1] 0.14</code></pre>
<p>The adjusted <span class="math inline">\(R^2\)</span> for the reduced model is pretty bad, but so is the full model! It will definitely be easier to interpret the reduced model</p>
<p>Now! We are all set to produce some ordination plots</p>
</div>
<div id="tri" class="section level3" number="4.4.5">
<h3><span class="header-section-number">4.4.5</span> Triplots: Graphing a constrained ordination</h3>
<p>If the constrained ordination is significant, we go on to display the results graphically. All ordination results of vegan can be displayed with a plot command. For a constrained ordination we will want a triplot, which has three different things plotted: the data objects, the response variables and the explanatory variables. For the varespec and varechem data these will be sites, species, and environmental predictors respectively.</p>
<p>Plotting an biplot or triplot is not as simple as it sounds, as I mentioned above, one can choose various scaling conventions that will dramatically change the appearance and interpretation of the plot. One of the editors of the vegan package, Gavin Simpson, has more to say about this <a href="https://fromthebottomoftheheap.net/2015/10/08/user-friendly-scaling/">here</a>. Essentially, there can be no scaling (“none”), or either the data object (“site”) or characteristic (“species”) scores are scaled by eigenvalues, and the other set of scores is left unscaled, or both scores are scaled symmetrically by square root of eigenvalues (“symmetric”). The general advice is to use scaling for “sites” where you want a biplot focussed on the sites/samples and the (dis)similarity between them in terms of the species (or variables), and use scaling for “species” where you want to best represent the correlations between species (or variables). I’ve plotted the “site” and “species” types below (Fig. <a href="multi.html#fig:triplotscale2">4.21</a>). Were you able to produce the same ordinations?</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb72-1"><a href="multi.html#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb72-2"><a href="multi.html#cb72-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-3"><a href="multi.html#cb72-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Triplots of the parsimonious RDA (scaling=1) Scaling 1</span></span>
<span id="cb72-4"><a href="multi.html#cb72-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(optm, <span class="at">scaling =</span> <span class="st">&quot;sites&quot;</span>, <span class="at">main =</span> <span class="st">&quot;Sites scaling (scaling=1)&quot;</span>,</span>
<span id="cb72-5"><a href="multi.html#cb72-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">correlation =</span> <span class="cn">TRUE</span>)</span>
<span id="cb72-6"><a href="multi.html#cb72-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-7"><a href="multi.html#cb72-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Triplots of the parsimonious RDA (scaling=2) Scaling 2</span></span>
<span id="cb72-8"><a href="multi.html#cb72-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(optm, <span class="at">scaling =</span> <span class="st">&quot;species&quot;</span>, <span class="at">main =</span> <span class="st">&quot;Species scaling (scaling=2)&quot;</span>)</span></code></pre></div>
<div class="figure"><span id="fig:triplotscale2"></span>
<img src="_main_files/figure-html/triplotscale2-1.png" alt="Two plots each with with y-axis labelled 'RDA2' and x-axis labelled 'RDA1' contains the variable names of the species in the varaspec dataset and site numbers respectively. Three arrows emerge from the center, 'P', 'Mn', and 'Fe'" width="672" />
<p class="caption">
Figure 4.21: Triplots of an RDA ordination on the lichen data with either site or species scaling using a basic plot command
</p>
</div>
<p>Its pretty hard to see what is going on in these basic plots, so I am going to take the time to produce more curated versions. I am going to select which species data I display, and the change the appearance and axis limits somewhat.</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb73-1"><a href="multi.html#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb73-2"><a href="multi.html#cb73-2" aria-hidden="true" tabindex="-1"></a>sp.scores <span class="ot">=</span> <span class="fu">scores</span>(optm, <span class="at">display =</span> <span class="st">&quot;species&quot;</span>, <span class="at">scaling =</span> <span class="dv">1</span>)</span>
<span id="cb73-3"><a href="multi.html#cb73-3" aria-hidden="true" tabindex="-1"></a>sp.scores <span class="ot">=</span> sp.scores[sp.scores[, <span class="dv">1</span>] <span class="sc">&gt;</span> <span class="fu">abs</span>(<span class="fl">0.1</span>) <span class="sc">|</span> sp.scores[,</span>
<span id="cb73-4"><a href="multi.html#cb73-4" aria-hidden="true" tabindex="-1"></a>    <span class="dv">2</span>] <span class="sc">&gt;</span> <span class="fu">abs</span>(<span class="fl">0.1</span>), ]</span>
<span id="cb73-5"><a href="multi.html#cb73-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-6"><a href="multi.html#cb73-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-7"><a href="multi.html#cb73-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(optm, <span class="at">scaling =</span> <span class="dv">1</span>, <span class="at">type =</span> <span class="st">&quot;n&quot;</span>, <span class="at">main =</span> <span class="st">&quot;Sites scaling (scaling=1)&quot;</span>,</span>
<span id="cb73-8"><a href="multi.html#cb73-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.2</span>, <span class="fl">0.2</span>), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.3</span>, <span class="fl">0.5</span>))</span>
<span id="cb73-9"><a href="multi.html#cb73-9" aria-hidden="true" tabindex="-1"></a><span class="fu">arrows</span>(<span class="at">x0 =</span> <span class="dv">0</span>, <span class="at">y0 =</span> <span class="dv">0</span>, sp.scores[, <span class="dv">1</span>], sp.scores[, <span class="dv">2</span>], <span class="at">length =</span> <span class="fl">0.05</span>)</span>
<span id="cb73-10"><a href="multi.html#cb73-10" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(sp.scores, <span class="fu">row.names</span>(sp.scores), <span class="at">col =</span> <span class="dv">2</span>, <span class="at">cex =</span> <span class="fl">0.6</span>, <span class="at">pos =</span> <span class="dv">3</span>)</span>
<span id="cb73-11"><a href="multi.html#cb73-11" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(optm, <span class="at">display =</span> <span class="st">&quot;bp&quot;</span>, <span class="at">scaling =</span> <span class="dv">1</span>, <span class="at">cex =</span> <span class="fl">0.8</span>, <span class="at">lwd =</span> <span class="fl">1.5</span>,</span>
<span id="cb73-12"><a href="multi.html#cb73-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">row.names</span>(<span class="fu">scores</span>(optm, <span class="at">display =</span> <span class="st">&quot;bp&quot;</span>)), <span class="at">col =</span> <span class="dv">4</span>)</span>
<span id="cb73-13"><a href="multi.html#cb73-13" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(optm, <span class="at">display =</span> <span class="fu">c</span>(<span class="st">&quot;sites&quot;</span>), <span class="at">scaling =</span> <span class="dv">1</span>, <span class="at">cex =</span> <span class="dv">1</span>)</span></code></pre></div>
<div class="figure"><span id="fig:triplotscale3"></span>
<img src="_main_files/figure-html/triplotscale3-1.png" alt="A plot with y-axis labelled 'RDA2' and x-axis labelled 'RDA1' contain the variable names of the species in the varaspec dataset and site numbers. There are three arrows that emerge from the center, 'P', 'Fe', and 'Mn'." width="672" />
<p class="caption">
Figure 4.22: Triplot of an RDA ordination on the lichen data with site scaling
</p>
</div>
<div class="sourceCode" id="cb74"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb74-1"><a href="multi.html#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(optm, <span class="at">scaling =</span> <span class="dv">2</span>, <span class="at">type =</span> <span class="st">&quot;n&quot;</span>, <span class="at">main =</span> <span class="st">&quot;Species scaling (scaling=2)&quot;</span>,</span>
<span id="cb74-2"><a href="multi.html#cb74-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.4</span>, <span class="fl">0.4</span>))</span>
<span id="cb74-3"><a href="multi.html#cb74-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-4"><a href="multi.html#cb74-4" aria-hidden="true" tabindex="-1"></a><span class="fu">arrows</span>(<span class="at">x0 =</span> <span class="dv">0</span>, <span class="at">y0 =</span> <span class="dv">0</span>, sp.scores[, <span class="dv">1</span>], sp.scores[, <span class="dv">2</span>], <span class="at">length =</span> <span class="fl">0.05</span>)</span>
<span id="cb74-5"><a href="multi.html#cb74-5" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(sp.scores, <span class="fu">row.names</span>(sp.scores), <span class="at">col =</span> <span class="dv">2</span>, <span class="at">cex =</span> <span class="fl">0.7</span>, <span class="at">pos =</span> <span class="dv">3</span>)</span>
<span id="cb74-6"><a href="multi.html#cb74-6" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(optm, <span class="at">display =</span> <span class="st">&quot;bp&quot;</span>, <span class="at">scaling =</span> <span class="dv">2</span>, <span class="at">cex =</span> <span class="fl">0.8</span>, <span class="at">lwd =</span> <span class="fl">1.5</span>,</span>
<span id="cb74-7"><a href="multi.html#cb74-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">row.names</span>(<span class="fu">scores</span>(optm, <span class="at">display =</span> <span class="st">&quot;bp&quot;</span>)), <span class="at">col =</span> <span class="dv">4</span>)</span>
<span id="cb74-8"><a href="multi.html#cb74-8" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(optm, <span class="at">display =</span> <span class="fu">c</span>(<span class="st">&quot;sites&quot;</span>), <span class="at">scaling =</span> <span class="dv">2</span>, <span class="at">cex =</span> <span class="dv">1</span>)</span></code></pre></div>
<div class="figure"><span id="fig:triplotscale4"></span>
<img src="_main_files/figure-html/triplotscale4-1.png" alt="A plot similar to the previous with different scaling based on species." width="672" />
<p class="caption">
Figure 4.23: Triplot of an RDA ordination on the lichen data with species scaling
</p>
</div>
<p>Okay, let’s figure out how to interpret these plots. In the site scaling option (Fig <a href="multi.html#fig:triplotscale3">4.22</a>), dissimilarity distances between data objects are preserved. So, sites which are closer together on the ordination are more similar. In addition, the projection of a data object (site) onto the line of a response variable (species) at right angle approximates the position of the corresponding object along the corresponding variable. Angles between lines of response variables (species) and lines of explanatory variables are a two-dimensional approximation of correlations. But other angles between lines are meaningless (e.g., angles between response vectors don’t mean anything).</p>
<p>In the species scaling plot (Fig <a href="multi.html#fig:triplotscale4">4.23</a>), distances are now meaningless, and as a result the length of vectors are not important. However, the cosine of the angle between lines of the response variables or of explanatory variables is approximately equal to the correlation between the corresponding variables.</p>
<p>So, looking at our first plot, sites 2, 28 and perhaps 3 seem quite different from others. For site 3, this is perhaps because of the abundance of <em>Cladrang</em>, which might be responding to iron levels (Fe). Site 28 might differ because of higher abundances of <em>Hylosple</em>, which may be related to Mn. Notice how we can see on the species scaling plot the strong correlation between P and species <em>Dicrsp</em>, which is somewhat different on the site scaling plot.</p>
<div id="what-next" class="section level4" number="4.4.5.1">
<h4><span class="header-section-number">4.4.5.1</span> What next?</h4>
<p>In this short introduction we have not demonstrated how to complete and interpret other forms of constrained ordination such as <strong>C</strong>anonical <strong>C</strong>orrespondence <strong>A</strong>nalysis, partial RDA (which would allow you to control for well-known linear effects), or analysis designed for qualiticative variables, such as <strong>M</strong>ultiple <strong>C</strong>orrespondence <strong>A</strong>nalysis (MCA). There are functions in the vegan and FactoMineR packages to do many of these things.</p>
</div>
</div>
<div id="feedback-3" class="section level3" number="4.4.6">
<h3><span class="header-section-number">4.4.6</span> Feedback</h3>
<p>We value your input! Please take the time to let us know how we might improve these materials. <a href="https://forms.gle/vLkcZq7NxPb2ajTQ6">Survey</a></p>
</div>
</div>
<div id="references" class="section level2" number="4.5">
<h2><span class="header-section-number">4.5</span> References</h2>
<p>Borcard, D., Gillet, F., &amp; Legendre, P. (2011). Numerical ecology with R. New York: springer.</p>
<p>Goodall, D. W. (1954). Objective methods for the classification of vegetation. III. An essay in the use of factor analysis. Australian Journal of Botany, 2(3), 304–324. <a href="https://doi.org/10.1071/bt9540304" class="uri">https://doi.org/10.1071/bt9540304</a></p>
<p>Greenacre, M. (2017). Ordination with any dissimilarity measure: A weighted Euclidean solution. Ecology, 98(9), 2293–2300. <a href="https://doi.org/10.1002/ecy.1937" class="uri">https://doi.org/10.1002/ecy.1937</a></p>
<p>Hotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417–441. <a href="https://doi.org/10.1037/h0071325" class="uri">https://doi.org/10.1037/h0071325</a></p>
<p>Legendre, P., &amp; Anderson, M. J. (1999). Distance-Based Redundancy Analysis: Testing Multispecies Responses in Multifactorial Ecological Experiments. Ecological Monographs, 69(1), 1–24. <a href="https://doi.org/10.1890/0012-9615(1999)069%5B0001:DBRATM%5D2.0.CO;2" class="uri">https://doi.org/10.1890/0012-9615(1999)069[0001:DBRATM]2.0.CO;2</a></p>
<p>Legendre, P., &amp; De Cáceres, M. (2013). Beta diversity as the variance of community data: Dissimilarity coefficients and partitioning. Ecology Letters, 16(8), 951–963. <a href="https://doi.org/10.1111/ele.12141" class="uri">https://doi.org/10.1111/ele.12141</a></p>
<p>Legendre, P., &amp; Gallagher, E. D. (2001). Ecologically meaningful transformations for ordination of species data. Oecologia, 129(2), 271–280. <a href="https://doi.org/10.1007/s004420100716" class="uri">https://doi.org/10.1007/s004420100716</a></p>
<p>Legendre, P., &amp; Legendre, L. (2012). Numerical ecology. Elsevier.</p>
<p>Pearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. <a href="https://doi.org/10.1080/14786440109462720" class="uri">https://doi.org/10.1080/14786440109462720</a></p>
<p>Perkins, M. J., McDonald, R. A., Veen, F. J. F. van, Kelly, S. D., Rees, G., &amp; Bearhop, S. (2014). Application of Nitrogen and Carbon Stable Isotopes (δ15N and δ13C) to Quantify Food Chain Length and Trophic Structure. PLOS ONE, 9(3), e93281. <a href="https://doi.org/10.1371/journal.pone.0093281" class="uri">https://doi.org/10.1371/journal.pone.0093281</a></p>
<p>Pielou, E. C. (1984). The interpretation of ecological data: A primer on classification and ordination. John Wiley &amp; Sons.</p>
<p>Rao, C. R. (1964). The Use and Interpretation of Principal Component Analysis in Applied Research. Sankhyā: The Indian Journal of Statistics, Series A (1961-2002), 26(4), 329–358. <a href="https://www.jstor.org/stable/25049339" class="uri">https://www.jstor.org/stable/25049339</a></p>
<p>Ter Braak, C. J. (1988). CANOCO-a FORTRAN program for canonical community ordination by partial detrended canonical correspondence analysis, principal components analysis and redundancy analysis (version 2.1). MLV.</p>
<p>Watson, N. H. F., &amp; Carpenter, G. F. (1974). Seasonal Abundance of Crustacean Zooplankton and Net Plankton Biomass of Lakes Huron, Erie, and Ontario. Journal of the Fisheries Research Board of Canada, 31(3), 309–317. <a href="https://doi.org/10.1139/f74-050" class="uri">https://doi.org/10.1139/f74-050</a></p>
<p>van den Wollenberg, A. L. (1977). Redundancy analysis an alternative for canonical correlation analysis. Psychometrika, 42(2), 207–219. <a href="https://doi.org/10.1007/BF02294050" class="uri">https://doi.org/10.1007/BF02294050</a></p>
</div>
<div id="answer-key" class="section level2" number="4.6">
<h2><span class="header-section-number">4.6</span> Answer Key</h2>
<p><strong>Exercise 1.</strong> All we need to do is to take the square root of the sum of the squared differences to obtain the Euclidean distance as</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb75-1"><a href="multi.html#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">sqrt</span>(eu[<span class="dv">11</span>, <span class="dv">4</span>]), <span class="dv">2</span>)</span></code></pre></div>
<pre class="Rout"><code>[1] 62</code></pre>
<p><strong>Exercise 2.</strong> We use the <strong>kmeans()</strong> function with 4 clusters to find groups in the isotope data. We can then save the assigned clusters to our dataframe and plot in a similar way</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb77-1"><a href="multi.html#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co"># select 4 clusters and run the kmeans function</span></span>
<span id="cb77-2"><a href="multi.html#cb77-2" aria-hidden="true" tabindex="-1"></a>kclust <span class="ot">=</span> <span class="fu">kmeans</span>(niso[, <span class="fu">c</span>(<span class="st">&quot;C&quot;</span>, <span class="st">&quot;N&quot;</span>)], <span class="dv">4</span>)</span>
<span id="cb77-3"><a href="multi.html#cb77-3" aria-hidden="true" tabindex="-1"></a>niso<span class="sc">$</span>kclust <span class="ot">=</span> kclust<span class="sc">$</span>cluster</span>
<span id="cb77-4"><a href="multi.html#cb77-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-5"><a href="multi.html#cb77-5" aria-hidden="true" tabindex="-1"></a><span class="co"># superimpose the saved clusters on our plotted isotope</span></span>
<span id="cb77-6"><a href="multi.html#cb77-6" aria-hidden="true" tabindex="-1"></a><span class="co"># data</span></span>
<span id="cb77-7"><a href="multi.html#cb77-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(iso<span class="sc">$</span>N <span class="sc">~</span> iso<span class="sc">$</span>C, <span class="at">col =</span> <span class="fu">as.numeric</span>(<span class="fu">as.factor</span>(niso<span class="sc">$</span>clust)),</span>
<span id="cb77-8"><a href="multi.html#cb77-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">35</span>, <span class="dv">0</span>), <span class="at">pch =</span> <span class="fu">as.numeric</span>(<span class="fu">as.factor</span>(niso<span class="sc">$</span>Species)),</span>
<span id="cb77-9"><a href="multi.html#cb77-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="fu">expression</span>(<span class="fu">paste</span>(delta, <span class="st">&quot;13C&quot;</span>)), <span class="at">ylab =</span> <span class="fu">expression</span>(<span class="fu">paste</span>(delta,</span>
<span id="cb77-10"><a href="multi.html#cb77-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;15N&quot;</span>)))</span>
<span id="cb77-11"><a href="multi.html#cb77-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-12"><a href="multi.html#cb77-12" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">legend =</span> <span class="fu">unique</span>(<span class="fu">as.factor</span>(niso<span class="sc">$</span>kclust)), <span class="at">pch =</span> <span class="dv">1</span>,</span>
<span id="cb77-13"><a href="multi.html#cb77-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">col =</span> <span class="fu">as.numeric</span>(<span class="fu">unique</span>(<span class="fu">as.factor</span>(niso<span class="sc">$</span>kclust))), <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>,</span>
<span id="cb77-14"><a href="multi.html#cb77-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;kcluster&quot;</span>)</span>
<span id="cb77-15"><a href="multi.html#cb77-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-16"><a href="multi.html#cb77-16" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;bottomright&quot;</span>, <span class="at">legend =</span> <span class="fu">as.character</span>(<span class="fu">unique</span>(<span class="fu">as.factor</span>(niso<span class="sc">$</span>Species))),</span>
<span id="cb77-17"><a href="multi.html#cb77-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">pch =</span> <span class="fu">as.numeric</span>(<span class="fu">unique</span>(<span class="fu">as.factor</span>(niso<span class="sc">$</span>Species))), <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>,</span>
<span id="cb77-18"><a href="multi.html#cb77-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;Species&quot;</span>)</span></code></pre></div>
<div class="figure"><span id="fig:kclust"></span>
<img src="_main_files/figure-html/kclust-1.png" alt="X-axis labelled 'd13C', y-axis labelled 'd15N'and two legends, one as 'kcluster' ranging from 1 to 4, and the second with 'Species'. Moving from left to right on the x-axis, '1' goes from bottom to top with all species, '4' is near midde with 'Diplazon' and 'Hoverfly', '2' is near the middle with all but 'Diplazon', and '3' is directly under with two 'Plant'." width="672" />
<p class="caption">
Figure 4.24: K means clustering on Perkins et al (2014) data for 4 clusters
</p>
</div>
<p>It looks like kmeans has the same problem with distinguishing C3 plant-based foodwebs. But we still get three groups that roughly map onto our information about the data.</p>
<p><strong>Exercise 3.</strong> Interpretation of the PCoA and the nMDS oridination plots of the varespec data is straightforward: sites ordinated closer to one another are more similar than those ordinated further away. We can interpret the nMDS, remembering that the first ordination axis corresponds to the most variance in our data and so on. Looking at the plot, it seems that sites 28, 27 and possibly 21 are pretty similar to each other, and different from other sites, possibly due to the species aligned in that direction on the x-axis such as <em>Betupube</em>. Sites 2 and 5 might be rather different from other sites. This might be due species like <em>Cladcerv</em> for site 2. Some sites (e.g., 6, 13, 20) are not well distinguished by the ordination. Others like 9, 10, 11, and 12 might group together.</p>
<p>PCoA gives us broadly the same information and also suggests that sites 21, 28, 27 are similar to each other and different from other sites. This visualization also agrees that sites 2 and 5 might be different from the others, and that 9, 10, 11, and 12 might be similar.</p>
<p><strong>Exercise 4.</strong> The automatically selected rda model of the lichen data includes three significant predictors: Fe, P and Mn, while the full model has 14 potential predictors. Our manually selected model of three predictors N, K and Al don’t even appear in the automatically selected model.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="r-markdown.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="machine-learning-and-classification.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
