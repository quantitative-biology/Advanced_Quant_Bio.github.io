newyear2$Station_Acronym=stvec[2]
newyear3 = newyear1
newyear3$Station_Acronym=stvec[3]
newYear=rbind(newyear1,newyear2,newyear3)
newYear$Station_Acronym=as.factor(newYear$Station_Acronym)
## Predict from the fitted model; note we predict from the $gam part
newYear <- cbind(newYear, data.frame(predict(m$gam, newYear, se.fit = TRUE)))
## Create the confidence interval
crit.t <- qt(0.975, df = df.residual(m$gam))
newYear <- transform(newYear,
upper = fit + (crit.t * se.fit), lower = fit - (crit.t * se.fit))
mscale=c(min(newYear$lower)-sscal,
max(pdat$metric, na.rm=T)+sscal)
plot(metric~year, data=pdat, xaxt="n",pch=16, col=pdat$Station_Acronym,
ann=FALSE, xlim=xyear,ylim=mscale, las=2)
if ( i==3)axis(side=1, las=1)
legend("bottomleft",stlabel[i], bty="n",
cex=1.5)
abline(v=1994, col="red", lwd=2)
for (i in 1:3){
datpl=newYear[newYear$Station_Acronym==stvec[i],]
lines(datpl$fit~datpl$year, lwd=2,col=i)
lines(upper~year, data=datpl,col="purple")
lines(lower~year, data=datpl,col="purple")
x=c(rev(datpl$lower), datpl$upper)
y=c(rev(datpl$year), datpl$year)
polygon(y,x, col=adjustcolor("grey",alpha.f=0.1), border=NA )
}
nsim=50
small.d <- fderiv(m, newdata = newYear, n = N)
small.sint <- with(newYear,
cbind(confint(small.d, nsim = nsim, type = "simultaneous"),
Year = year))
rscale=c(min(small.sint$lower)-sscal,sscal)
ticks <- round(seq(from=rscale[1], to=rscale[2], length=6),2)
if (mmetric=="epar" & i==2) {
ticks=c(-0.05, -0.03, -0.01, 0.00,  0.01)
rscale=c(min(small.sint$lower),sscal)
}
plot(small.sint$est~small.sint$Year,ann=FALSE,xaxt = "n",
type="l", lwd=2,xaxt="n",col=i,yaxt="n",
ylim=rscale,xlim=xyear, las=2)
if ( i==3) {axis(side=1, las=1)}
if (i==2) {mtext(rlab,cex=1.3,line=4,side=2 ) }
axis(side=2,  las=1, at=ticks, labels=ticks )
lines(lower~Year, data=small.sint, col="green")
lines(upper~Year, data=small.sint, col="green")
x=c(rev(small.sint$lower), small.sint$upper)
y=c(rev(small.sint$Year), small.sint$Year)
polygon(y,x, col=adjustcolor("green",alpha.f=0.1), border=NA )
abline(h=0, lwd=2, col=adjustcolor("dark gray",alpha.f=0.75))
abline(v=1994, col="red", lwd=2)
#legend("bottomright",stlabel[i], bty="n",cex=1.5)
rm(list=ls())
#install.packages("mgcv")
#this package fits a GAM
library("mgcv")
#install.packages("devtools")
#library("devtools")
#devtools::install_github("gavinsimpson/gratia")
#this package calcuates the finite difference of a GAM curve
library("gratia")
#read in data supplied by DFO, rename and aggregate into annuual means
colnames(my_data)[colnames(my_data)=="Epar#Ship"] <- "epar"
colnames(my_data)[colnames(my_data)=="Secchi_depth#Ship"] <- "secchi"
colnames(my_data)[colnames(my_data)=="Chl_a_uncorrected#GLLFAS"] <- "Chla"
colnames(my_data)[colnames(my_data)=="TOTAL_Daphnia_BM"]<-"daphnia"
colnames(my_data)[colnames(my_data)=="Total Phyto biomass searching Excel files"]<-"Phyto_BM"
mmetric="TP" #select which metric to analyze
#mlab=expression(Light~attenuation~(m^-1))
mlab=expression(Chlorophyll~a~(mu~g~L^-1))
#mlab=expression(Total~phosophorus~(mg~L^-1))
#rlab=expression(Rate~of~change~(mg~L^-1~year^-1))
rlab=expression(Rate~of~change~(m^-1~year^-1))
#rlab=expression(Rate~of~change~(mu~g~L^-1~year^-1))
#sscal=0.0001 #phosophorus and round 3
sscal=1.25 #clorophyll and round 1
sscal=0.005 #phosophorus and round 3
#aggregate and run analysis on selected sites
frm=paste(mmetric,"~ Station_Acronym+year")
spydat=aggregate(as.formula(frm), my_data, length)
mdat=aggregate(as.formula(frm), my_data, mean)
colnames(spydat)[3]="n"
spydat[4]=mdat[3]
colnames(spydat)[4]="metric"
spydat$weights <- spydat$n/mean(spydat$n)
#select sites on which to run analysis
stvec=c("B", "HB",  "C")
stlabel=c("Belleville", "Hay Bay", "Conway")
#par(mfrow=c(3,2), mar=c(0,4,0,3), oma=c(5,5,2,2),cex.axis=1.25)
#spydat=pln
#doing this analysis for each site
#for (i in 1:length(stvec)) {
#pdat<-spydat[spydat$Station_Acronym==stvec[i],]
pdat<-spydat[spydat$Station_Acronym%in%stvec,]
if (stvec[i]=="C" & mmetric=="TP") pdat=pdat[-nrow(pdat),]
pdat=pdat[pdat$year%in%c(1972:2015),]
#  xyear=c(1972,2015)
xyear=c(1972,2015)
pdat$Station_Acronym=as.factor(pdat$Station_Acronym)
str(pdat)
N=1000 #number of points at which to evaluate the smooth
#m <- gamm(metric ~ s(year, by=Station_Acronym,k = 20)+Station_Acronym , data = pdat, weights=weights,
#correlation=corCAR1(form = ~year|Station_Acronym),
3method = "ML")
m <- gamm(metric ~ s(year, by=Station_Acronym,k = 20)+Station_Acronym , data = pdat, weights=weights,
correlation=corCAR1(form = ~year|Station_Acronym),
method = "REML")
summary(m$gam)
summary(m$lme)
## create new data to predict at; 200 evenly-spaced values over `Year`
newyear1 <- with(pdat, data.frame(year = seq(min(year), max(year), length.out = 200)))
newyear1$Station_Acronym=stvec[1]
newyear2 = newyear1
newyear2$Station_Acronym=stvec[2]
newyear3 = newyear1
newyear3$Station_Acronym=stvec[3]
newYear=rbind(newyear1,newyear2,newyear3)
newYear$Station_Acronym=as.factor(newYear$Station_Acronym)
## Predict from the fitted model; note we predict from the $gam part
newYear <- cbind(newYear, data.frame(predict(m$gam, newYear, se.fit = TRUE)))
## Create the confidence interval
crit.t <- qt(0.975, df = df.residual(m$gam))
newYear <- transform(newYear,
upper = fit + (crit.t * se.fit), lower = fit - (crit.t * se.fit))
mscale=c(min(newYear$lower)-sscal,
max(pdat$metric, na.rm=T)+sscal)
plot(metric~year, data=pdat, xaxt="n",pch=16, col=pdat$Station_Acronym,
ann=FALSE, xlim=xyear,ylim=mscale, las=2)
if ( i==3)axis(side=1, las=1)
legend("bottomleft",stlabel[i], bty="n",
cex=1.5)
abline(v=1994, col="red", lwd=2)
for (i in 1:3){
datpl=newYear[newYear$Station_Acronym==stvec[i],]
lines(datpl$fit~datpl$year, lwd=2,col=i)
lines(upper~year, data=datpl,col="purple")
lines(lower~year, data=datpl,col="purple")
x=c(rev(datpl$lower), datpl$upper)
y=c(rev(datpl$year), datpl$year)
polygon(y,x, col=adjustcolor("grey",alpha.f=0.1), border=NA )
}
nsim=50
small.d <- fderiv(m, newdata = newYear, n = N)
small.sint <- with(newYear,
cbind(confint(small.d, nsim = nsim, type = "simultaneous"),
Year = year))
rscale=c(min(small.sint$lower)-sscal,sscal)
ticks <- round(seq(from=rscale[1], to=rscale[2], length=6),2)
if (mmetric=="epar" & i==2) {
ticks=c(-0.05, -0.03, -0.01, 0.00,  0.01)
rscale=c(min(small.sint$lower),sscal)
}
plot(small.sint$est~small.sint$Year,ann=FALSE,xaxt = "n",
type="l", lwd=2,xaxt="n",col=i,yaxt="n",
ylim=rscale,xlim=xyear, las=2)
if ( i==3) {axis(side=1, las=1)}
if (i==2) {mtext(rlab,cex=1.3,line=4,side=2 ) }
axis(side=2,  las=1, at=ticks, labels=ticks )
lines(lower~Year, data=small.sint, col="green")
lines(upper~Year, data=small.sint, col="green")
x=c(rev(small.sint$lower), small.sint$upper)
y=c(rev(small.sint$Year), small.sint$Year)
polygon(y,x, col=adjustcolor("green",alpha.f=0.1), border=NA )
abline(h=0, lwd=2, col=adjustcolor("dark gray",alpha.f=0.75))
abline(v=1994, col="red", lwd=2)
#legend("bottomright",stlabel[i], bty="n",cex=1.5)
rm(list=ls())
#install.packages("mgcv")
#this package fits a GAM
library("mgcv")
#install.packages("devtools")
#library("devtools")
#devtools::install_github("gavinsimpson/gratia")
#this package calcuates the finite difference of a GAM curve
library("gratia")
#read in data supplied by DFO, rename and aggregate into annuual means
colnames(my_data)[colnames(my_data)=="Epar#Ship"] <- "epar"
colnames(my_data)[colnames(my_data)=="Secchi_depth#Ship"] <- "secchi"
colnames(my_data)[colnames(my_data)=="Chl_a_uncorrected#GLLFAS"] <- "Chla"
colnames(my_data)[colnames(my_data)=="TOTAL_Daphnia_BM"]<-"daphnia"
colnames(my_data)[colnames(my_data)=="Total Phyto biomass searching Excel files"]<-"Phyto_BM"
mmetric="TP" #select which metric to analyze
#mlab=expression(Light~attenuation~(m^-1))
mlab=expression(Chlorophyll~a~(mu~g~L^-1))
#mlab=expression(Total~phosophorus~(mg~L^-1))
#rlab=expression(Rate~of~change~(mg~L^-1~year^-1))
rlab=expression(Rate~of~change~(m^-1~year^-1))
#rlab=expression(Rate~of~change~(mu~g~L^-1~year^-1))
#sscal=0.0001 #phosophorus and round 3
sscal=1.25 #clorophyll and round 1
sscal=0.005 #phosophorus and round 3
#aggregate and run analysis on selected sites
frm=paste(mmetric,"~ Station_Acronym+year")
spydat=aggregate(as.formula(frm), my_data, length)
mdat=aggregate(as.formula(frm), my_data, mean)
colnames(spydat)[3]="n"
spydat[4]=mdat[3]
colnames(spydat)[4]="metric"
spydat$weights <- spydat$n/mean(spydat$n)
#select sites on which to run analysis
stvec=c("B", "HB",  "C")
stlabel=c("Belleville", "Hay Bay", "Conway")
#par(mfrow=c(3,2), mar=c(0,4,0,3), oma=c(5,5,2,2),cex.axis=1.25)
#spydat=pln
#doing this analysis for each site
#for (i in 1:length(stvec)) {
#pdat<-spydat[spydat$Station_Acronym==stvec[i],]
pdat<-spydat[spydat$Station_Acronym%in%stvec,]
if (stvec[i]=="C" & mmetric=="TP") pdat=pdat[-nrow(pdat),]
pdat=pdat[pdat$year%in%c(1972:2015),]
#  xyear=c(1972,2015)
xyear=c(1972,2015)
pdat$Station_Acronym=as.factor(pdat$Station_Acronym)
str(pdat)
N=1000 #number of points at which to evaluate the smooth
#m <- gamm(metric ~ s(year, by=Station_Acronym,k = 20)+Station_Acronym , data = pdat, weights=weights,
#correlation=corCAR1(form = ~year|Station_Acronym),
3method = "ML")
m <- gamm(metric ~ s(year, by=Station_Acronym,k = 20)+Station_Acronym , data = pdat, weights=weights,
correlation=corCAR1(form = ~year|Station_Acronym),
method = "REML")
summary(m$gam)
summary(m$lme)
## create new data to predict at; 200 evenly-spaced values over `Year`
newyear1 <- with(pdat, data.frame(year = seq(min(year), max(year), length.out = 200)))
newyear1$Station_Acronym=stvec[1]
newyear2 = newyear1
newyear2$Station_Acronym=stvec[2]
newyear3 = newyear1
newyear3$Station_Acronym=stvec[3]
newYear=rbind(newyear1,newyear2,newyear3)
newYear$Station_Acronym=as.factor(newYear$Station_Acronym)
## Predict from the fitted model; note we predict from the $gam part
newYear <- cbind(newYear, data.frame(predict(m$gam, newYear, se.fit = TRUE)))
## Create the confidence interval
crit.t <- qt(0.975, df = df.residual(m$gam))
newYear <- transform(newYear,
upper = fit + (crit.t * se.fit), lower = fit - (crit.t * se.fit))
mscale=c(min(newYear$lower)-sscal,
max(pdat$metric, na.rm=T)+sscal)
plot(metric~year, data=pdat, xaxt="n",pch=16, col=pdat$Station_Acronym,
ann=FALSE, xlim=xyear,ylim=mscale, las=2)
if ( i==3)axis(side=1, las=1)
legend("bottomleft",stlabel[i], bty="n",
cex=1.5)
abline(v=1994, col="red", lwd=2)
for (i in 1:3){
datpl=newYear[newYear$Station_Acronym==stvec[i],]
lines(datpl$fit~datpl$year, lwd=2,col=i)
lines(upper~year, data=datpl,col="purple")
lines(lower~year, data=datpl,col="purple")
x=c(rev(datpl$lower), datpl$upper)
y=c(rev(datpl$year), datpl$year)
polygon(y,x, col=adjustcolor("grey",alpha.f=0.1), border=NA )
}
nsim=50
small.d <- fderiv(m, newdata = newYear, n = N)
rm(list=ls())
#install.packages("mgcv")
#this package fits a GAM
library("mgcv")
#install.packages("devtools")
#library("devtools")
#devtools::install_github("gavinsimpson/gratia")
#this package calcuates the finite difference of a GAM curve
library("gratia")
#read in data supplied by DFO, rename and aggregate into annuual means
colnames(my_data)[colnames(my_data)=="Epar#Ship"] <- "epar"
colnames(my_data)[colnames(my_data)=="Secchi_depth#Ship"] <- "secchi"
colnames(my_data)[colnames(my_data)=="Chl_a_uncorrected#GLLFAS"] <- "Chla"
colnames(my_data)[colnames(my_data)=="TOTAL_Daphnia_BM"]<-"daphnia"
colnames(my_data)[colnames(my_data)=="Total Phyto biomass searching Excel files"]<-"Phyto_BM"
mmetric="TP" #select which metric to analyze
#mlab=expression(Light~attenuation~(m^-1))
mlab=expression(Chlorophyll~a~(mu~g~L^-1))
#mlab=expression(Total~phosophorus~(mg~L^-1))
#rlab=expression(Rate~of~change~(mg~L^-1~year^-1))
rlab=expression(Rate~of~change~(m^-1~year^-1))
#rlab=expression(Rate~of~change~(mu~g~L^-1~year^-1))
#sscal=0.0001 #phosophorus and round 3
sscal=1.25 #clorophyll and round 1
sscal=0.005 #phosophorus and round 3
#aggregate and run analysis on selected sites
frm=paste(mmetric,"~ Station_Acronym+year")
spydat=aggregate(as.formula(frm), my_data, length)
mdat=aggregate(as.formula(frm), my_data, mean)
colnames(spydat)[3]="n"
spydat[4]=mdat[3]
colnames(spydat)[4]="metric"
spydat$weights <- spydat$n/mean(spydat$n)
#select sites on which to run analysis
stvec=c("B", "HB",  "C")
stlabel=c("Belleville", "Hay Bay", "Conway")
#par(mfrow=c(3,2), mar=c(0,4,0,3), oma=c(5,5,2,2),cex.axis=1.25)
#spydat=pln
#doing this analysis for each site
#for (i in 1:length(stvec)) {
#pdat<-spydat[spydat$Station_Acronym==stvec[i],]
pdat<-spydat[spydat$Station_Acronym%in%stvec,]
if (stvec[i]=="C" & mmetric=="TP") pdat=pdat[-nrow(pdat),]
pdat=pdat[pdat$year%in%c(1972:2015),]
#  xyear=c(1972,2015)
xyear=c(1972,2015)
pdat$Station_Acronym=as.factor(pdat$Station_Acronym)
str(pdat)
rm(list=ls())
#install.packages("mgcv")
#this package fits a GAM
library("mgcv")
#install.packages("devtools")
#library("devtools")
#devtools::install_github("gavinsimpson/gratia")
#this package calcuates the finite difference of a GAM curve
library("gratia")
#read in data supplied by DFO, rename and aggregate into annuual means
library(openxlsx)
my_data <-(as.data.frame(read.xlsx("E:/homeoffice/kim/transients/quinte data/QUINTE.xlsx")))
colnames(my_data)[colnames(my_data)=="Epar#Ship"] <- "epar"
colnames(my_data)[colnames(my_data)=="Secchi_depth#Ship"] <- "secchi"
colnames(my_data)[colnames(my_data)=="Chl_a_uncorrected#GLLFAS"] <- "Chla"
colnames(my_data)[colnames(my_data)=="TOTAL_Daphnia_BM"]<-"daphnia"
colnames(my_data)[colnames(my_data)=="Total Phyto biomass searching Excel files"]<-"Phyto_BM"
mmetric="TP" #select which metric to analyze
#mlab=expression(Light~attenuation~(m^-1))
mlab=expression(Chlorophyll~a~(mu~g~L^-1))
#mlab=expression(Total~phosophorus~(mg~L^-1))
#rlab=expression(Rate~of~change~(mg~L^-1~year^-1))
rlab=expression(Rate~of~change~(m^-1~year^-1))
#rlab=expression(Rate~of~change~(mu~g~L^-1~year^-1))
#sscal=0.0001 #phosophorus and round 3
sscal=1.25 #clorophyll and round 1
sscal=0.005 #phosophorus and round 3
#aggregate and run analysis on selected sites
frm=paste(mmetric,"~ Station_Acronym+year")
spydat=aggregate(as.formula(frm), my_data, length)
mdat=aggregate(as.formula(frm), my_data, mean)
colnames(spydat)[3]="n"
spydat[4]=mdat[3]
colnames(spydat)[4]="metric"
spydat$weights <- spydat$n/mean(spydat$n)
#select sites on which to run analysis
stvec=c("B", "HB",  "C")
stlabel=c("Belleville", "Hay Bay", "Conway")
#par(mfrow=c(3,2), mar=c(0,4,0,3), oma=c(5,5,2,2),cex.axis=1.25)
#spydat=pln
#doing this analysis for each site
#for (i in 1:length(stvec)) {
#pdat<-spydat[spydat$Station_Acronym==stvec[i],]
pdat<-spydat[spydat$Station_Acronym%in%stvec,]
if (stvec[i]=="C" & mmetric=="TP") pdat=pdat[-nrow(pdat),]
pdat=pdat[pdat$year%in%c(1972:2015),]
#  xyear=c(1972,2015)
xyear=c(1972,2015)
pdat$Station_Acronym=as.factor(pdat$Station_Acronym)
str(pdat)
N=1000 #number of points at which to evaluate the smooth
rm(list=ls())
#install.packages("mgcv")
#this package fits a GAM
library("mgcv")
#install.packages("devtools")
#library("devtools")
#devtools::install_github("gavinsimpson/gratia")
#this package calcuates the finite difference of a GAM curve
library("gratia")
#read in data supplied by DFO, rename and aggregate into annuual means
library(openxlsx)
my_data <-(as.data.frame(read.xlsx("E:/homeoffice/kim/transients/quinte data/QUINTE.xlsx")))
colnames(my_data)[colnames(my_data)=="Epar#Ship"] <- "epar"
colnames(my_data)[colnames(my_data)=="Secchi_depth#Ship"] <- "secchi"
colnames(my_data)[colnames(my_data)=="Chl_a_uncorrected#GLLFAS"] <- "Chla"
colnames(my_data)[colnames(my_data)=="TOTAL_Daphnia_BM"]<-"daphnia"
colnames(my_data)[colnames(my_data)=="Total Phyto biomass searching Excel files"]<-"Phyto_BM"
mmetric="TP" #select which metric to analyze
#mlab=expression(Light~attenuation~(m^-1))
mlab=expression(Chlorophyll~a~(mu~g~L^-1))
#mlab=expression(Total~phosophorus~(mg~L^-1))
#rlab=expression(Rate~of~change~(mg~L^-1~year^-1))
rlab=expression(Rate~of~change~(m^-1~year^-1))
#rlab=expression(Rate~of~change~(mu~g~L^-1~year^-1))
#sscal=0.0001 #phosophorus and round 3
sscal=1.25 #clorophyll and round 1
sscal=0.005 #phosophorus and round 3
#aggregate and run analysis on selected sites
frm=paste(mmetric,"~ Station_Acronym+year")
spydat=aggregate(as.formula(frm), my_data, length)
mdat=aggregate(as.formula(frm), my_data, mean)
colnames(spydat)[3]="n"
spydat[4]=mdat[3]
colnames(spydat)[4]="metric"
spydat$weights <- spydat$n/mean(spydat$n)
#select sites on which to run analysis
stvec=c("B", "HB",  "C")
stlabel=c("Belleville", "Hay Bay", "Conway")
#par(mfrow=c(3,2), mar=c(0,4,0,3), oma=c(5,5,2,2),cex.axis=1.25)
#spydat=pln
#doing this analysis for each site
#for (i in 1:length(stvec)) {
#pdat<-spydat[spydat$Station_Acronym==stvec[i],]
pdat<-spydat[spydat$Station_Acronym%in%stvec,]
#if (stvec[i]=="C" & mmetric=="TP") pdat=pdat[-nrow(pdat),]
pdat=pdat[pdat$year%in%c(1972:2015),]
#  xyear=c(1972,2015)
xyear=c(1972,2015)
pdat$Station_Acronym=as.factor(pdat$Station_Acronym)
str(pdat)
N=1000 #number of points at which to evaluate the smooth
m <- gamm(metric ~ s(year, by=Station_Acronym,k = 20)+Station_Acronym , data = pdat, weights=weights,
correlation=corCAR1(form = ~year|Station_Acronym),
method = "REML")
summary(m$gam)
## create new data to predict at; 200 evenly-spaced values over `Year`
newyear1 <- with(pdat, data.frame(year = seq(min(year), max(year), length.out = 200)))
newyear1$Station_Acronym=stvec[1]
newyear2 = newyear1
newyear2$Station_Acronym=stvec[2]
newyear3 = newyear1
newyear3$Station_Acronym=stvec[3]
newYear=rbind(newyear1,newyear2,newyear3)
newYear$Station_Acronym=as.factor(newYear$Station_Acronym)
## Predict from the fitted model; note we predict from the $gam part
newYear <- cbind(newYear, data.frame(predict(m$gam, newYear, se.fit = TRUE)))
## Create the confidence interval
crit.t <- qt(0.975, df = df.residual(m$gam))
newYear <- transform(newYear,
upper = fit + (crit.t * se.fit), lower = fit - (crit.t * se.fit))
mscale=c(min(newYear$lower)-sscal,
max(pdat$metric, na.rm=T)+sscal)
plot(metric~year, data=pdat, xaxt="n",pch=16, col=pdat$Station_Acronym,
ann=FALSE, xlim=xyear,ylim=mscale, las=2)
if ( i==3)axis(side=1, las=1)
legend("bottomleft",stlabel[i], bty="n",
cex=1.5)
abline(v=1994, col="red", lwd=2)
for (i in 1:3){
datpl=newYear[newYear$Station_Acronym==stvec[i],]
lines(datpl$fit~datpl$year, lwd=2,col=i)
lines(upper~year, data=datpl,col="purple")
lines(lower~year, data=datpl,col="purple")
x=c(rev(datpl$lower), datpl$upper)
y=c(rev(datpl$year), datpl$year)
polygon(y,x, col=adjustcolor("grey",alpha.f=0.1), border=NA )
}
nsim=50
small.d <- fderiv(m, newdata = newYear, n = N)
small.sint <- with(newYear,
cbind(confint(small.d, nsim = nsim, type = "simultaneous"),
Year = year))
rscale=c(min(small.sint$lower)-sscal,sscal)
ticks <- round(seq(from=rscale[1], to=rscale[2], length=6),2)
if (mmetric=="epar" & i==2) {
ticks=c(-0.05, -0.03, -0.01, 0.00,  0.01)
rscale=c(min(small.sint$lower),sscal)
}
summary(small.d)
summary(small.d$derivatives)
summary(small.d$derivatives$s(year):Station_AcronymB )
small.d$derivatives$s(year):Station_AcronymB
small.d$derivatives[[1]]
str(small.d$derivatives[[1]])
## create new data to predict at; 200 evenly-spaced values over `Year`
newyear1 <- with(pdat, data.frame(year = seq(min(year), max(year), length.out = 10)))
newyear1$Station_Acronym=stvec[1]
newyear2 = newyear1
newyear2$Station_Acronym=stvec[2]
newyear3 = newyear1
newyear3$Station_Acronym=stvec[3]
newYear=rbind(newyear1,newyear2,newyear3)
newYear$Station_Acronym=as.factor(newYear$Station_Acronym)
## Predict from the fitted model; note we predict from the $gam part
newYear <- cbind(newYear, data.frame(predict(m$gam, newYear, se.fit = TRUE)))
## Create the confidence interval
crit.t <- qt(0.975, df = df.residual(m$gam))
newYear <- transform(newYear,
upper = fit + (crit.t * se.fit), lower = fit - (crit.t * se.fit))
mscale=c(min(newYear$lower)-sscal,
max(pdat$metric, na.rm=T)+sscal)
plot(metric~year, data=pdat, xaxt="n",pch=16, col=pdat$Station_Acronym,
ann=FALSE, xlim=xyear,ylim=mscale, las=2)
if ( i==3)axis(side=1, las=1)
legend("bottomleft",stlabel[i], bty="n",
cex=1.5)
abline(v=1994, col="red", lwd=2)
for (i in 1:3){
datpl=newYear[newYear$Station_Acronym==stvec[i],]
lines(datpl$fit~datpl$year, lwd=2,col=i)
lines(upper~year, data=datpl,col="purple")
lines(lower~year, data=datpl,col="purple")
x=c(rev(datpl$lower), datpl$upper)
y=c(rev(datpl$year), datpl$year)
polygon(y,x, col=adjustcolor("grey",alpha.f=0.1), border=NA )
}
nsim=50
small.d <- fderiv(m, newdata = newYear, n = N)
small.d[[1]]
small.sint <- with(newYear,
cbind(confint(small.d, nsim = nsim, type = "simultaneous"),
Year = year))
confint(small.d, nsim = nsim, type = "simultaneous")
confint(small.d)
confint(small.d)
confint
gratia::confint()
confint.fderiv()
gratia::confint.fderiv()
add_confint()
?add_confint
confint(small.d, type = "simultaneous")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
setwd("C:/github/Basics")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
